
\section{Introduction}

\input{input/figpartitionintuition.tex} %% positioning

In recent years, the data storage paradigm shifted from centralized in
the cloud to distributed at the edges of the network. 
% There is an ongoing evolution of storing data from the cloud to the
% edges of the network.
This shift aims at keeping the data close to
\begin{inparaenum}[(i)]
\item its producers since data may be too expensive or sensitive to be
  transmitted through the network; and
\item its consumers so data may quickly and efficiently reach
  them~\cite{cachier, foggy_cache, shi2016edge}.
\end{inparaenum}
%% It avoids transmitting Either because it is where it has been
%% created and it is too expensive to be transmitted through the
%% network, or because it has been replicated to bring data closer to
%% the end users ~\cite{shi2016edge, foggy_cache, cachier}.
%
To favour this transition, new designs for data management across Edge
infrastructures have been investigated~\cite{confais2017object,
  confais2017performance, fogstore, hasenburg2020towards}.  They
enable strategies to confine traffic by writing data locally and
replicating content according to effective needs. However, locating
content remains challenging. Retrieving a content location may
actually take more time than retrieving the content itself.
%% Although
%% these systems, provide good properties such as favouring network
%% traffic confinement by writting data locally and replicating contents
%% according to the effective needs, determining the location where to
%% get the content might be more expensive than retrieving the content
%% itself.
%
Indeed, these systems, when not using a centralized index hosted in a
Cloud~\REF, rely on distributed hash
tables~\cite{maymounkov2002kademlia} spread across the different
\processes composing the infrastructure. When a client wants to access
specific content, it requests a remote \process to provide at least
one \process identity to retrieve this content from. After it
retrieved the content, the client can create another replica to
improve the performance of future accesses, but it must contact the
content indexing service again to notify of such change.
%% a local replica is created to improve the performance for future
%% accesses and the process in charge of maintaining the index is
%% contacted once again to reflect this new location.
%

%This strategy has two majors drawbacks :
%\begin{itemize}
%  \item (i) the lookup penalty: the network latency to reach this
%    remote node incurs an additional delay~\cite{asrese2019measuring,
%      doan2019tracing} to get the object before
%    being able to start its downloading ;
%  \item (ii) the selection of the node(s) from which the content is
%    returned: due to the lack of information that would allow the  a request to each process storing a
%%    replica is perfomed in
%\end{itemize}

These approaches directly contradict with the objectives of Edge
infrastructures that aim at reducing the impact of latency as well as
the volume of data passing through the network.
%
First, accessing a remote \node to request content location(s) raises
hot spots and availability issues. But most importantly, it results in
additional delays that occur even before the actual download
started~\cite{asrese2019measuring, doan2019tracing}.
%
Second, the client gets a list of content locations at the discretion
of content indexing services. Without information about these
locations, it often ends up downloading from multiple replica hosts,
yet only keeping the fastest answer~\REF. In turns, either clients
waste network resources, or face lower response time. 
%% there is no information to select the ``best'' node among the
%% possible candidates from which the content could be retrieved. In
%% most cases, this results in parallel requests performed by the
%% client node to each candidate with the goal of retrieving the
%% content as efficient as possible.

To tackle aforementioned limitations, every \process that might
request or replicate content must also host its own content indexing
service in a fully decentralized fashion~\cite{kermarrec2015want}. At
any time, it can immediately locate the closest replica of specific
content.  A naive approach would be that every \process indexes and
ranks \emph{every live} replica along with its \emph{location}
information. When creating or destroying a replica, a \process would
notify all other \processes by efficiently broadcasting its
operation~\cite{birman1999bimodal, hadzilacos1994modular,
  raynal2013distributed}. Unfortunately, this also contradicts with
Edge infrastructure objectives, for such protocol does not confine the
traffic generated to maintain its indexes. A \process may acknowledge
the existence of replicas at the other side of the network while there
already exists a replica right next to it.

Instead, a \process creating a replica should notify all and only
\processes that have no closer replica. This would create
interconnected sets of \processes, or \emph{partitions}, gathered
around a \emph{source} being their respective replica. A \process
deleting its replica should notify all members of its partition so
they can rally their current closest partition. A periodic
advertisement protocol already provides both these operations for
routing purposes~\cite{hemmati2015namebased}. However, its functioning
requires
\begin{inparaenum}[(i)]
\item to generate traffic even when the system is quiescent, and
\item to finely tune physical-time-based intervals that depend on
  network topology parameters such as network diameter.
\end{inparaenum}

%% A ``simple'' way to tackle the aforementioned limitations would be to
%% maintain on each node composing the infrastructure and for each
%% content, an index of all replicas (and their ``distance'').  In such
%% an approach, each time a new replica is created or deleted, a message
%% is broadcasted from the node that performed the operation (\ie the
%% source) to all nodes, increasing the distance information at each hop.
%% %
%% In addition to being complicated for large-scale systems, maintaining
%% a global view on each node is useless as there is no interest to
%% inform a node of the creation/removal of a replica at the opposite of
%% the network (each node trying to get content from the ``closest''
%% one).  In other words, the broadcast should be limited to a partition
%% of the infrastructure, (\ie the subset of nodes that has to update the
%% current location for this particular content). Obviously, these
%% partitions depend and evolve according to concurrent operations made
%% by nodes (replica creation/removal) as well as dynamic changes in the
%% infrastructure (network failures, node apparitions/leaves).

In this paper, we propose a first implementation of such a protocol.
Entitled Adaptive Scoped broadcast (\NAME), 
our protocol relies on a primitive that forwards
messages until a certain condition is reached, \ie the scope. The
scope is defined by a boolean function (predicate) that returns
whether a message should be propagated or not around its
broadcaster. In the current scenario, the stop condition is related to
the distance to the nearest replica : if the message that a node receives
indicates a content has a longer distance than that which the node
knows then the transfer of the message is useless and so stopped.
%
This primitive is used to guarantee that eventually, every node knows
its best partition, hence its closest replica, despite concurrent
events and receipt orders. Overall, \NAME is a wait-free reactive protocol for
dynamic logical partitioning.  Its overhead actually depends on
its operations and current partitions in the system. When the system
becomes quiescent, nodes eventually converge to their respective
partition and do not require further communication afterward.

\TODO{talk about the proof}

We evaluated our protocol through two simulation scenarios using
\textit{Peersim}~\cite{montresor2009peersim}. First, we confirm that
\NAME allow consistent partitioning in an ad-hoc network composed of
10K nodes.  Second, we illustrate how \NAME enables the lock down of
the traffic in dynamic inter autonomous systems.  More precisely, we
simulated a worldwilde infrastructure by duplicating the GEANT
topology - a real infrastructure spanning across Europe â€“ and by
connecting these two clusters with a high latency link: 200 ms
simulating cross-continental communications such as Europe-America.

%\input{input/figadd.tex} %% positioning (belong to problem & motivation)

The rest of this paper is organized as
follows. Section~\ref{sec:background} introduces background, and
details the motivation behind our proposal.
Section~\ref{sec:adaptive} describes the protocol behavior, as well
as the formal definition of the underlying
algorithms. Section~\ref{sec:experimentation} presents the Peersim
evaluations.  Related work is discussed in
Section~\ref{sec:related_work} and finally
Section~\ref{sec:conclusion} concludes this article and highlights a
few future works.
  

%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "../paper"
%%% ispell-local-dictionary: "english"
%%% End: 
