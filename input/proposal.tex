
\section{Dynamic partitioning}
\label{sec:proposal}

\TODO{Remember to say stateless, asynchronous system.}

In this section, we introduce \NAME, (\TODO{stands for}) a reactive
protocol for logical partitioning the cost of which actually depends
on its usage: when the system becomes quiescent, processes eventually
converge to their respective partition and do not require further
communication afterwards.

Each process works autonomously and each change is broadcast to its
neighborhood, for neighbors may depend on this change as well. 

% The main idea is maintaining graphs of partitions using local
% knowledge only and use graphs as often as possible: it improves
% resilience to crashes, convergence speed etc. Unfortunately,
% maintaining graphs of partitions in dynamic networks may require the
% use of broadcast tree. The removal of a communication channel between
% 2 processes may remove an advantageous path from processes downstream
% to the source of the partition they belong to.

This section describes \NAME's components by starting from the
simplest case of add-only partition, to the most complex case of
dynamic partitions in dynamic networks. 

\TODO{Probably better to pair operation as ``ins, del'' and ``add, rem''?}

\begin{algorithm}
  \input{input/algoadddelundo.tex}
  \caption{\label{algo:adddelundo}Dynamic partitioning by Process $p$.}
\end{algorithm}


\paragraph{Static network with add-only.}
At any time, a process can become a source, hence \TODO{creating} a
new partition in the system. This partition eventually includes all
processes that are closer from this new source than any other else. We
described such protocol in Section~\ref{sec:background}. Processes
naturally converge towards their respective best partition by only
piggybacking a monotonically increasing distance in forwarded
messages.  \TODO{Traffic of each partition is contained to the
  partition.}

\paragraph{Static network with dynamic partitions.}
At any time, a source can revoke its self-appointed status of source,
hence \TODO{removing} its partition of the system. All processes that
belong to this partition must choose another partition to belong to.

\noindent Since the number of partitions does not monotonically
increase in the system any longer, they require a vector of versions
that monotonically increases over \TODO{add and del} operations. This
allows processes to quickly discard stale messages saving
bandwidth. For instance, a process that received a message originated
at Process $a$ with a version $2$ knows that any message originated at
Process $a$ with a version $1$ are stale system-wide; it must not
forward it. As consequence, vectors of versions also ensure
termination, for messages \TODO{add and del} cannot follow each other
in an infinite loop. In terms of traffic, this only requires each
\TODO{delete} message to piggyback a source identifier and version
number.

% \noindent \textbf{Second,} processes need to maintain a local view of
% their neighbors' partition.  Figure~\ref{fig:del} shows that
% \TODO{deletes} may not propagate properly to all processes in
% need. The path leading to processes delivering $add$ may be broken due
% to concurrent deliveries.  To solve this issue, each process is able
% to know with certainty that each of its neighbor does not need a
% delete (either because it is in another partition, or because another
% path exists from the source to this neighbor). \TODO{More, figures
%   etc.} In terms of traffic, this requires to acknowledge each message
% in a way or another (acknowledgement messages or included in each
% add-del message) using FIFO communication channels. The propagation of
% delete messages is limited to the partition it targets plus uncertain
% processes.

\noindent Deletes must trigger competition amongst neighboring
partitions. These \TODO{add} messages operate normally and fill gaps
left open by deletes.

\begin{figure*}
  \begin{center}
    \subfloat[Part A][\label{fig:proofA}Stale $\alpha$'s may stop up-to-date $\alpha$'s
    from reaching all processes that require it along the shortest path from $a$ to $c$.
    To solve this issue, we must guarantee
    the eventual removal of stale $\alpha$'s (see Figure~\ref{fig:proofB}).]
    {\input{input/figproofA.tex}}
    \hspace{10pt}
    \subfloat[Part B][\label{fig:proofB}Stale $\alpha$'s may stop $\delta$'s from reaching
    processes with targeted $\alpha$'s. To ensure correctness, $b$ must either
    deliver $\delta_d$, $\delta_d^{0.5}$, or another $\alpha$, as well as downstream processes
    that delivered $\alpha$ coming from $b$ such as $g$.]
    {\input{input/figproofB.tex}}
    \caption{\label{fig:proof}Dynamic partitioning leads to correctness issues due to
      staleness and ordering of operations.}
  \end{center}
\end{figure*}

\paragraph{Networks with new communication links.}
Adding new communication links to the network may create shortcuts
between processes. Both processes must send their current best
partition to each other. Upon receipt, they act normally: if a process
finds out that the received partition is closer than its current one,
it delivers it which in turns also triggers another competition
amongst neighbors due to forwarding.

\noindent Joining the network is equivalent to add as many
communication links as necessary between the joining process and its
new neighbors.

\begin{algorithm}
  \input{input/algoedges.tex}
  \caption{\label{algo:edges}Dynamic partitioning by Process $p$ in dynamic networks.}
\end{algorithm}


\paragraph{Dynamic networks with dynamic partitions.}
When removing a communication link between two processes does not
break any active path, because neither distances of processes depend
on the other, then nothing needs to be done. \NAME has no overhead.
Unfortunately, when a process' distance depends on the other process,
the protocol becomes much more complex. Indeed, this requires to
\TODO{undo} all add messages originated from this process. A message
must convey the fact that
\begin{inparaenum}[(i)]
\item an edge at a particular process has been removed, and
\item the distance that has been delivered by a process comes from
  this particular process.
\end{inparaenum}

\noindent \NAME handles this as a particular case of partition within
current partition: it contains to affected regions the traffic
generated to patch affected regions. In order to know if it is
affected by the \TODO{undo} operation, using distances already
piggybacked in messages is not sufficient.  Each process must know the
path taken by delivered message. Since we do not beforehand which
communication links will crash and which messages will be affected by
undos, each message has to carry its path along forwarding. This also
allows processes to remove loops, for they cannot rely on version
number (that remains unchanged) for this operation.

\noindent Instead of version number, one could use such paths to remove loops
due to \TODO{add and del}, however this may be much more costly in
terms of generated traffic. Version numbers guarantee that only one
delete is delivered and all prior inserts are then discarded, while
using paths, processes may deliver multiple inserts and deletes before
reaching termination. \TODO{maybe clearer with figures.} As
consequence, \NAME still makes use of vector of versions.

\noindent Although costly, piggybacking paths with logical partitioning synergies
well, for the size of these paths decreases quickly as the number of
partitions grows.

\paragraph{A last optimisation}
\TODO{Carry information that is useless. such as order of processes in
  paths, and identities of processes themselves.} \TODO{Icarus for
  dissemination trees~\cite{whitaker2002forwarding}}. \TODO{No need to
  know the dimension of networks and
  partitions~\cite{almeida2007scalable}}.

\subsection{Complexity}
\label{subsec:complexity}

\TODO{To rework, for there are more components now. Maybe do this
  along the description of the approach.}

We focus on average-case and worst-case complexity. We divide our
analysis into space, time, and communication complexity.

\textbf{The communication complexity} concerns the size and number of
messages required to reach optimal partitioning. In the average-case,
a process $i$ chosen uniformly at random among all processes creates a
logical partition. Its messages $\alpha_i$ propagate through the
network until reaching processes that belong to another partition
closer to them. This splits partitions in half in average. Overall,
the $a^{th}$ new partition comprises
\smash{$\mathcal{O}(\frac{|V|}{2^{\lfloor \log_2 a \rfloor}})$}
processes. This decreases every new partition until reaching $0$
processes per new partition: even the chosen process already belongs
to its optimal partition. The average number of messages per process
is \smash{$\mathcal{O}(\frac{\overline{|O|}}{2^{\lfloor \log_2 a
      \rfloor}})$}. \TODO{Multiple receipt and multiple delivery imply
  more messages (receipt bounded by $|O|$ as well).} Deleting the
$a^{th}$ partition generates the exact same number of messages than
the $a^{th}$ partition creation. \TODO{But what about echos?} In the
worst-case, every new partition includes all but one process belonging
to the previous partition. The total number of messages after the
$a^{th}$ new partition is $\mathcal{O}(\overline{|O|}\cdot a^2)$. As
for the average-case, the number of messages for the partition
deletion is identical to the number of messages of the corresponding
partition creation.

%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "../paper"
%%% ispell-local-dictionary: "english"
%%% End: 
