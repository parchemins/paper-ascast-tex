
\section{\NAME for Dynamic Partitioning}
\label{sec:proposal}

In this section, we introduce \NAME, (\TODO{stands for}) a reactive
protocol for logical partitioning in autonomous systems the cost of
which actually depends on its usage: when the system becomes
quiescent, processes eventually converge to their respective partition
and do not require further communication afterwards.

Each process is stateless, works autonomously and asynchronously, in a
peer-to-peer fashion. Each process broadcasts each change to its
neighborhood, for the state of its neighbors may depend on this change
as well. Yet, generated traffic remains \TODO{low} using scoped
flooding. Messages that carry changes travel through the network
depending on partition of processes, stopping as soon as they
encounter uninterested processes. We demonstrate that \NAME guarantees
consistent partitioning despite different order in message deliveries
from one process to another.

This section describes \NAME's components and algorithms. First, it
starts by detailing a logical partitioning protocol in static
network. Second, it extends such protocol to dynamic systems. Last, it
describes an optimization based on Bloom filter. 



\subsection{Autonomous systems}

\begin{figure}
  \centering\input{input/figAS.tex}
  \caption{\label{fig:AS}Inter autonomous systems partitioning. \TODO{new
      issue not introduced in background}}
\end{figure}

Autonomous systems are geo-distributed networks. Heterogeneous
communication links. Hierarchy of communication links. Per-object
broadcast.

We leave the link handling to membership protocols~\REF. The ordering
of links can be done based on latency. For instance, from 0 to 100 ms,
rank 0, from 100 to 1s, rank 2 \ldots

\begin{algorithm}
  \input{input/algoaaaa.tex}
  \caption{\label{algo:aaaa}Primitives for general purpose logical
    partitioning in dynamic systems.}
\end{algorithm}

Figure~\ref{fig:AS} shows an example of inter-AS logical partitioning
where each process ranks its communication links, and each process
forwards messages to its neighbors starting from the rank of the link
that triggered the receipt, to its highest rank neighbors. In this
example, Process $e$ adds a partition. It forwards the generated
message to all its neighbors as if it received it from its lowest rank
links. When Process $a$ receives $\alpha_e^1$ from its rank-$0$ link,
it forwards it to rank-$0$ links and rank-$1$ links.  Process $b$
stops the propagation, for all its links have lower ranks than the one
from which it received the message $\alpha_e^2$. Ultimately, the
partition includes Process $e$, Process $a$, and Process $b$. Process
$c$ and Process $d$ remain unaware of the new \TODO{object}.

\TODO{Not so easy\ldots}

\subsection{Dynamic partitions}

\begin{algorithm}
  \input{input/algoadddelundo.tex}
  \caption{\label{algo:adddelundo}Dynamic partitioning by Process $p$.}
\end{algorithm}

At any time, a process can become a source, hence adding a new
partition to the system. This partition eventually includes all
processes that are closer from this new source than any other else. We
described such protocol in Section~\ref{sec:background}. Processes
naturally converge towards their respective best partition by only
piggybacking a monotonically increasing distance in forwarded
messages. % \TODO{Traffic of each partition is contained to the
%  partition.}

Then, at any time, a source can revoke its self-appointed status of
source, hence deleting its partition from the system. All processes
that belong to this partition must eventually choose another partition
to belong to. Since the number of partitions does not monotonically
increase in the system any longer, each process requires a vector of
versions that monotonically increases over delivered operations.

This allows processes to quickly discard stale messages saving
bandwidth. For instance, a process that received a message originated
at Process $a$ with a version $2$ knows that any message originated at
Process $a$ with a version $1$ are stale system-wide; it must not
forward it. As consequence, vectors of versions also ensure
termination, for messages \TODO{add and del} cannot follow each other
in an infinite loop. In terms of traffic, this only requires each
\TODO{delete} message to piggyback a source identifier and version
number.

% \noindent \textbf{Second,} processes need to maintain a local view of
% their neighbors' partition.  Figure~\ref{fig:del} shows that
% \TODO{deletes} may not propagate properly to all processes in
% need. The path leading to processes delivering $add$ may be broken due
% to concurrent deliveries.  To solve this issue, each process is able
% to know with certainty that each of its neighbor does not need a
% delete (either because it is in another partition, or because another
% path exists from the source to this neighbor). \TODO{More, figures
%   etc.} In terms of traffic, this requires to acknowledge each message
% in a way or another (acknowledgement messages or included in each
% add-del message) using FIFO communication channels. The propagation of
% delete messages is limited to the partition it targets plus uncertain
% processes.

\noindent Deletes must trigger competition amongst neighboring
partitions. These \TODO{add} messages operate normally and fill gaps
left open by deletes.

\begin{figure*}
  \begin{center}
    \subfloat[Part A][\label{fig:proofA}Stale $\alpha$'s may stop up-to-date $\alpha$'s
    from reaching all processes that require it along the shortest path from $a$ to $c$.
    To solve this issue, we must guarantee
    the eventual removal of stale $\alpha$'s (see Figure~\ref{fig:proofB}).]
    {\input{input/figproofA.tex}}
    \hspace{10pt}
    \subfloat[Part B][\label{fig:proofB}Stale $\alpha$'s may stop $\delta$'s from reaching
    processes with targeted $\alpha$'s. To ensure correctness, $b$ must either
    deliver $\delta_d$, $\delta_d^{0.5}$, or another $\alpha$, as well as downstream processes
    that delivered $\alpha$ coming from $b$ such as $g$.]
    {\input{input/figproofB.tex}}
    \caption{\label{fig:proof}Dynamic partitioning leads to correctness issues due to
      staleness and ordering of operations.}
  \end{center}
\end{figure*}

\subsection{Dynamic networks}
Adding new communication links to the network may create shortcuts
between processes. Both processes must send their current best
partition to each other. Upon receipt, they act normally: if a process
finds out that the received partition is closer than its current one,
it delivers it which in turns also triggers another competition
amongst neighbors due to forwarding.

\noindent Joining the network is equivalent to add as many
communication links as necessary between the joining process and its
new neighbors.

\begin{algorithm}
  \input{input/algoedges.tex}
  \caption{\label{algo:edges}Dynamic partitioning by Process $p$ in dynamic networks.}
\end{algorithm}



When removing a communication link between two processes does not
break any active path, because neither distances of processes depend
on the other, then nothing needs to be done. \NAME has no overhead.
Unfortunately, when a process' distance depends on the other process,
the protocol becomes much more complex. Indeed, this requires to
\TODO{undo} all add messages originated from this process. A message
must convey the fact that
\begin{inparaenum}[(i)]
\item an edge at a particular process has been removed, and
\item the distance that has been delivered by a process comes from
  this particular process.
\end{inparaenum}

\noindent \NAME handles this as a particular case of partition within
current partition: it contains to affected regions the traffic
generated to patch affected regions. In order to know if it is
affected by the \TODO{undo} operation, using distances already
piggybacked in messages is not sufficient.  Each process must know the
path taken by delivered message. Since we do not beforehand which
communication links will crash and which messages will be affected by
undos, each message has to carry its path along forwarding. This also
allows processes to remove loops, for they cannot rely on version
number (that remains unchanged) for this operation.

\noindent Instead of version number, one could use such paths to remove loops
due to \TODO{add and del}, however this may be much more costly in
terms of generated traffic. Version numbers guarantee that only one
delete is delivered and all prior inserts are then discarded, while
using paths, processes may deliver multiple inserts and deletes before
reaching termination. \TODO{maybe clearer with figures.} As
consequence, \NAME still makes use of vector of versions.

\noindent Although costly, piggybacking paths with logical partitioning synergies
well, for the size of these paths decreases quickly as the number of
partitions grows.

\subsection{A last optimization}
\TODO{Carry information that is useless. such as order of processes in
  paths, and identities of processes themselves.} \TODO{Icarus for
  dissemination trees~\cite{whitaker2002forwarding}}. \TODO{No need to
  know the dimension of networks and
  partitions~\cite{almeida2007scalable}}.

\subsection{Complexity}
\label{subsec:complexity}

\TODO{To rework, for there are more components now. Maybe do this
  along the description of the approach.}

We focus on average-case and worst-case complexity. We divide our
analysis into space, time, and communication complexity.

\textbf{The communication complexity} concerns the size and number of
messages required to reach optimal partitioning. In the average-case,
a process $i$ chosen uniformly at random among all processes creates a
logical partition. Its messages $\alpha_i$ propagate through the
network until reaching processes that belong to another partition
closer to them. This splits partitions in half in average. Overall,
the $a^{th}$ new partition comprises
\smash{$\mathcal{O}(\frac{|V|}{2^{\lfloor \log_2 a \rfloor}})$}
processes. This decreases every new partition until reaching $0$
processes per new partition: even the chosen process already belongs
to its optimal partition. The average number of messages per process
is \smash{$\mathcal{O}(\frac{\overline{|O|}}{2^{\lfloor \log_2 a
      \rfloor}})$}. \TODO{Multiple receipt and multiple delivery imply
  more messages (receipt bounded by $|O|$ as well).} Deleting the
$a^{th}$ partition generates the exact same number of messages than
the $a^{th}$ partition creation. \TODO{But what about echos?} In the
worst-case, every new partition includes all but one process belonging
to the previous partition. The total number of messages after the
$a^{th}$ new partition is $\mathcal{O}(\overline{|O|}\cdot a^2)$. As
for the average-case, the number of messages for the partition
deletion is identical to the number of messages of the corresponding
partition creation.

%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "../paper"
%%% ispell-local-dictionary: "english"
%%% End: 
