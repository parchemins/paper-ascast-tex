
\section{Adaptive scoped broadcast}
\label{sec:adaptive}

To assign and maintain \processes to their best partition according to
replica creations and removals, as well as dynamic infrastructure
changes, we designed and implemented \NAME.  \NAME stands for
\underline{A}daptive \underline{S}coped broad\underline{cast}. It
relies on a primitive that allows a \process to broadcast a message
within a limited scope. We first use this primitive to guarantee
consistent partitioning when a \process can only create a new replica
within the system. We highlight the issue when a \process can also
destroy a replica, and provide a second algorithm that handles replica
removals as well as dynamic changes of the infrastructure.  This
section describes the communication primitive called scoped broadcast,
then discusses the properties that guarantee consistent partitioning,
and finally details our implementation \NAME.
% and the analysis of its complexity.


\subsection{Scoped broadcast}
\label{subsec:scoped}

%For instance, a \process from Paris could scoped broadcast messages to
%all \processes in Paris; and \processes from other cities would never
%deliver such messages.
%Scoped broadcast only targets a connected \emph{subset} of \processes
%in the whole distributed system.
%

% \TODO{dynamic graph: superscript with $t$?}
In this paper, we consider Edge infrastructures with heterogeneous
\nodes interconnected by communication links. \Processes involved in
the management of content may crash but are not byzantine.  \Processes
can reliably communicate through asynchronous message passing to other
known \processes called neighbors.  % A more formal
%definition of our system is given below:
We define scoped broadcast as a communication primitive that
propagates a message around its broadcaster within an
application-dependant scope.

\begin{definition}[Edge infrastructure]
  An Edge infrastructure is a connected \underline{g}raph $G(V, E)$ of
  \underline{v}ertices $V$ and bidirectional \underline{e}dges $E
  \subseteq V \times V$.  A \underline{p}ath $\pi_{ij}$ from
  \Process~$i$ to \Process~$j$ is a sequence of vertices $[i, k_1,
    k_2, \ldots k_n, j]$ with $\forall m: 0\leq m \leq n, \langle
  \pi_{ij}[m], \pi_{ij}[m+1] \rangle \in E$.
\end{definition}


%Using epidemic
%propagation (or gossiping), \processes can reliably broadcast messages
%by forwarding delivered messages from neighbors to
%neighbors~\cite{birman1999bimodal, hadzilacos1994modular,
%  nedelec2018causal, raynal2013distributed}.
%
%However, uniform reliable
%broadcast states that \emph{all} correct \processes must deliver all
%broadcast messages. This proves costly in large scale systems
%comprising thousands of \processes. Instead, we define \emph{scoped
%broadcast} where messages reach only an application-dependant subset
%of connected \processes, thus significantly reducing the generated
%traffic of broadcast.


\begin{definition}[\label{def:scoped}\underline{S}coped broad\underline{cast} (\NAMEB)]
  When \Process~$x$ scoped \underline{b}roadcasts $b_x(m)$ a
  \underline{m}essage $m$, every correct \process $y$ within a scope
  \underline{r}eceives $r_y(m)$ and \underline{d}elivers it
  $d_y(m)$. The scope depends on the \underline{s}tate $\sigma$ of
  each \process, the \underline{m}etadata $\mu$ piggybacked by each
  message, and a \underline{p}redicate $\phi$ verified from \process to
  \process: $b_x(m) \wedge r_y(m) \implies \exists \pi_{xy}: \forall z
  \in \pi_{xy}, \phi(\mu_z, \sigma_z)$.
\end{definition}

This definition encompasses more specific definitions of related
work~\cite{hsiao2005scoped, lue2006scoped, wang2015prodiluvian}.  It
also highlights that epidemic propagation and scoped broadcast have
well-aligned preoccupations. More precisely, it underlines the
transitive relevance of messages, thus a \process can stop forwarding
messages as soon as its predicate becomes unverified.
%For instance, a \process
%from Paris could scoped broadcast messages to all \processes in
%Paris. This requires \processes to store and maintain their city
%location in their local state. \Processes stop delivering and
%forwarding their received messages when they come from a different
%city.  In another instance, a \process from Paris could scoped
%broadcast messages to all \processes in Paris plus neighboring
%cities. This requires \processes to overload forwarded messages the
%first time they reach another city. The predicate checks if messages
%already reached two distinct cities before delivery. Similarly to
%uniform reliable broadcast, scoped broadcast implementations expose
%different trade-offs on space, time, and communication.
%
We use \NAMEB to efficiently modify the state of each \process
depending on the partitions that exist in the system.



\subsection{Consistent partitioning}
\label{subsec:consistent}

At any time, a \process can decide to become a \emph{source}, hence
creating a new partition in the system by executing an \texttt{Add}
operation. This partition includes at least its source plus
neighboring \processes that estimate they are closer to this source
than any other one. Such a distance (or \emph{weight}) is
application-dependant: in the context of maintaining distributed
indexes, this would be about link latency that \nodes could monitor
by aggregating \texttt{ping}s.

\begin{definition}[\label{def:partitioning}Partitioning]
  Let $S \subseteq V$ be the set of \underline{s}ources, and $P_s$ be
  the \underline{p}artition including at least \Process~$s$, each
  \process belongs to at most one partition $\forall p,q \in V, \forall
  s_1,s_2 \in S: p \in P_{s_1} \wedge q \in P_{s_2} \implies p \neq q
  \vee s_1 = s_2$, and there exists at least one path $\pi_{ps}$ of
  \processes that belong to this partition $\forall q \in \pi_{ps}: q
  \in P_s$.
\end{definition}

Definition~\ref{def:scoped} and Definition~\ref{def:partitioning}
share the transitive relevance of \process states. However, we further
constrain the partitioning in order to guarantee the existence of
exactly one consistent partitioning that \processes eventually converge
to.

\begin{definition}[\underline{C}onsistent \underline{p}artitioning (CP)]
  Let $W_{xy} = W_{yx}$ be the positive symmetric \underline{w}eight
  between $x$ and $y$, $\Pi_{xz}$ be the shortest \underline{p}ath
  from $x$ to $z$ the weight of which $|\Pi_{xz}|$ is lower than any
  other path weight, with $|\Pi_{xx}|$ being the greatest lower bound
  of $x$, the only consistent partitioning $\mathcal{P}$ is a set of
  partitions $P_{s\in S}$ such that each \process belongs to a logical
  partition comprising its closest source: $\forall p \in P_{s_1}:
  \nexists P_{s_2}$ such that $|\Pi_{s_2p}| < |\Pi_{s_1p}|$.
\end{definition}

Unfortunately, \processes do not share a common global knowledge of
the network state. For \processes to reach consistent partitioning
together, a \Process $s$ \underline{a}dding a partition must send a
notification $\alpha_s$ to every \process that is closer to it than
any other source. Since epidemic dissemination and scoped broadcast
have well-aligned preoccupations, we assume implementations relying on
message forwarding from neighbor-to-neighbor.

\begin{theorem}[\label{theo:efb}\underline{E}ventual \underline{F}orwarding
    of \underline{B}est $(EFB) \implies CP$] Assuming reliable
  communication links where a correct \process $q$ eventually receives
  the message $m$ \underline{s}ent to it by a \process $p$ ($s_{pq}(m)
  \implies r_{q}(m)$), \processes eventually reach consistent
  partitioning if each \process eventually \underline{f}orwards
  ($f_p(m) \implies \forall \langle p, q\rangle \in E: s_{pq}(m)$) its
  best known partition.
\end{theorem}

\input{input/figadd.tex} 

\begin{proof}
  When a \process $s_1$ becomes a source, it belongs to its own
  partition, for there exists no better partition than its own:
  $\forall p \in V: |\Pi_{s_1 s_1}| < |\Pi_{s_1 p}|$. It delivers,
  hence forwards such an $\alpha$ message to its neighbors. Since
  communication links are reliable, neighboring \processes eventually
  receive such a notification $\forall \langle s_1, q \rangle \in E,
  s_1 \in S \iff \eventually r_q(\alpha_{s_1}^{w_{s_1 q}})$. Most
  importantly, whatever the order of received messages, every \process
  $q'$ in this neighborhood -- such that there exists no better
  partition $s_2$ than the received one -- delivers and forwards it:
  $\forall s_2 \in S: |\Pi_{q' s_1}| < |\Pi_{q' s_2}| \implies
  \eventually d_{q'}(\alpha_{s_1}^{w_{s_1 q'}})$. By transitivity, the
  message originating from $s_1$ reaches all such \processes through
  their shortest paths: $\forall q'' \in V, s_1, s_2 \in S: |\Pi_{q''
    s_1}| < |\Pi_{q'' s_2}| \implies \eventually
  d_{q''}(\alpha_{s_1}^{|\Pi_{s_1 q''}|})$.  Since there exists only
  one best sum of weights per \process that can never be retracted,
  \processes eventually reach consistent partitioning.
  %% /!\ not equivalence for there exists other implementations.
  %% \item [$CP \implies BEF$:] By contradiction, if a \process $q \in
  %%   \Pi_{sp} = [s, \ldots, q, q', \ldots, p]$ with $s, q, p \in P_s$
  %%   does not forward its received $\alpha_s^{|\Pi_{sq}|}$, then
  %%   following \processes from $q'$ to $p$ may mistake another
  %%   partition for their  because it needs the weight $W_{pq}$.
  %% \end{asparadesc}
\end{proof}

\begin{algorithm}
  \input{input/algoadd.tex}
  \caption{\label{algo:add}Adding a partition by \Process~$p$.}
\end{algorithm}

Algorithm~\ref{algo:add} shows the instructions that implement
consistent partitioning when
\begin{inparaenum}[(i)]
\item weights are scalar values,
\item \processes only add new partitions to the system,
\item and \processes never crash nor leave the system.
\end{inparaenum}
Figure~\ref{fig:add} illustrates its behavior on a system comprising 4
\processes $a$, $b$, $c$, and $d$. \Process~$a$ and \Process~$d$
become the sources of their partition. They \NAMEB a notification
\underline{a}dd message: $\alpha_a^0$ and $\alpha_d^0$. They
initialize their own state with the lowest possible bound $0$ (see
Line~\ref{line:lowestbound}), and send a message to each of their
neighbors by accumulating the corresponding edge weight (see
Line~\ref{line:accumulator}). In Figure~\ref{fig:addC}, \Process~$b$
receives $\alpha_{d}^{1}$. Since it improves its own partition
distance, it keeps it and forwards it to its neighbors. In
Figure~\ref{fig:addD}, \Process~$b$ discards $\alpha_{a}^{2}$, for it
does not improve its partition distance. \Processes $c$ and $d$ will
never acknowledge that Source~$a$ exists. Ultimately, \processes
discard last transiting messages. Despite the obvious lack of traffic
optimization, the system reaches consistent partitioning.

While only adding logical partitions to the distributed system is
straightforward, removing them introduces additional complexity caused
by concurrent operations.

\subsection{Dynamic consistent partitioning}
\label{subsec:dynamic}

%% At any time, a \process can become a source, hence adding a new
%% partition to the system. This partition eventually includes all
%% \processes that are closer from this new source than any other
%% else. \Processes naturally converge towards their respective best
%% partition by only piggybacking a monotonically increasing distance in
%% forwarded messages.

At any time, a source can revoke its self-appointed status of source
by executing a \texttt{Del} operation, hence deleting its partition
from the system. All \processes that belong to this partition must
eventually choose another partition to belong to. In
Figure~\ref{fig:del}, two partitions exist initially: $P_a$ and $P_d$
that respectively include $\{a\}$, and $\{b, c, d\}$. In
Figure~\ref{fig:delA}, \Process~$a$ deletes its partition. It notifies
all neighboring \processes~--~here only \Process~$b$~-- that may
belong to its partition using \NAMEB. Upon receipt, \Process~$b$
discards the \underline{d}elete notification $\delta_a$ since
$\delta_a$ does not target the former's partition $P_d$. \Process~$b$
sends its own best partition $\alpha_d^3$ that may be the best for
\Process~$a$. Eventually, every \process belongs to Partition
$P_d$. In this scenario, they reach consistent partitioning.

Delete operations add a new notion of order between events, and most
importantly between message deliveries. Delete operations implicitly
state that all preceding events become obsolete, and that all messages
originating from these preceding events convey stale control
information.

\begin{definition}[Happens-before $\rightarrow$~\cite{lamport1978time}]
  The transitive, irreflexive, and antisymmetric happens-before
  relationship defines a strict partial order between events. Two
  messages are concurrent if none happens before the other.
\end{definition}

\begin{definition}[\label{def:lwo}Message staleness]
  Only the latest message of a \process matters. A message $m$ conveys
  \underline{s}tale control information if the \process that broadcast
  $m$ later broadcast another message $m'$: $S(m) = \exists m': b_p(m)
  \rightarrow b_p(m')$.

  %% When a \process $p$ broadcasts two messages $b_p(m) \rightarrow
  %% b_p(m')$, no \process $q$ can deliver $m$ if it has delivered $m'$:
  %% $\nexists q \in V$ with $d_q(m') \rightarrow d_q(m)$, for $m$
  %% convey \emph{\underline{s}tale} control information: $S(m)$.
\end{definition}

\input{input/figdel.tex}

\input{input/figsimplerproblem.tex}

Unfortunately, stale control information as stated in
Definition~\ref{def:lwo} may impair the propagation of both
\begin{inparaenum}[(i)]
\item notifications about actual sources, and
\item notifications about deleted partitions.
\end{inparaenum}
\TODO{Rework here.}
Figure~\ref{fig:problem} highlights such consistency issues with
dynamic partitions, even in contexts where \processes have FIFO links,
\ie where \processes receive the messages in the order of their
sending ($s_{pq}(m) \rightarrow s_{pq}(m') \implies r_q(m) \rightarrow
r_q(m')$). Both $a$ and $d$ add then delete their partition
concurrently. \Process~$c$ receives, delivers, and forwards
$\alpha_d^3$ followed by $\delta_d$. In the meantime, $b$ receives,
delivers, and forwards $\alpha_a^2$. In Figure~\ref{fig:problemC},
both $c$ and $d$ deliver the message about Partition $P_a$, for they
did not have any known partition at receipt time. On the contrary, $b$
delivers $\alpha_d^1$, for it improves its distance to a known
source. \Process~$b$ then blocks $a$'s removal notification
$\delta_a$. It never reaches $c$ nor $d$. Also, $c$ does not deliver
$\alpha_d$ and $\delta_d$ since it already delivered it. The system
converges to an inconsistent state where some \processes assume they
belong to a partition while it does not exist anymore. The system
needs to purge stale $\alpha$ messages that stop $\delta$ messages
from reaching nodes.

\begin{definition}[\label{def:purge}Message purge]
  A system purges a message $P(m)$ when every \node $q$ that delivered
  $m$ eventually delivers another message $m'$ never followed by the
  delivery of the former message $m$: $d_q(m) \implies \eventually
  (d_q(m) \rightarrow d_q(m'))$.
\end{definition}


\begin{theorem}[\label{theo:dcp}EFB$^+$: EFB $\wedge$ (Purge $\rightarrow$ EFB) $\implies$
    \underline{D}ynamic \underline{c}onsistent
    \underline{p}artitioning (DCP)]
%
  When a \process can \texttt{Add} and \texttt{Del}ete its partition,
  to ensure consistent partitioning, eventual forwarding of best
  (Theorem~\ref{theo:efb}) additionally requires
\begin{inparaenum}[(i)]
\item eventual purging of stale messages ($S(m) \implies P(m)$), then
\item the eventual forwarding of best (Definition~\ref{theo:efb}).
\end{inparaenum}
\end{theorem}

\begin{proof}
  %% To reach consistent partitioning, the last message delivered by
  %% every process is not stale and comes from its respective best
  %% source: $d(m)$
  Assuming EFB as default propagation behavior where \processes
  deliver and forward the best sum of weights they received. We must
  prove that despite stale messages, the last delivery of every
  \process is the message that followed the shortest path to its
  closest source.
  \begin{asparadesc}
  \item [EFB without Purge:] From Figure~\ref{fig:problemD}, a
    \process may receive messages in such an order ($d_b(\alpha_d^1)
    \rightarrow r_b(\delta_a) \rightarrow d_b(\delta_d)$) that it does
    not forward messages required by other \processes
    ($\delta_a$). The last delivery of some nodes ($c$ and $d$) is
    wrong ($\alpha_a^3$ instead of $\delta_a$).
    % \Processes never
    % reach consistent partitioning.
    %
    %% Figure~\ref{fig:proofA} depicts the generic case where a \process
    %% $b$ precludes itself and subsequent \processes such as $c$ of
    %% delivering the message from their respective best source
    %% $a$. \Process $b$ received and delivered a message from a
    %% partition that has since then been deleted but with a better sum
    %% of weights than newly received ones ($\alpha_d^y <
    %% \alpha_a^{x'}$). It forever discards such a message
    %% $\alpha_a^{x'}$.
  \item [Purge not followed by EFB:]
    %% also transiting messages
    Assuming that every \process removes control information as soon
    as it becomes stale ($S(\alpha_a) \implies d_b(\alpha_a^x)
    \rightarrow d_b(\delta_a)$) and cannot deliver stale messages
    anymore ($S(\alpha_a^x) \implies d_c(m) \rightarrow \ldots
    \rightarrow d_c(m' \not\in \alpha_a)$), staleness does not impair
    up-to-date messages propagation. However, even in such settings,
    depending on receipt order ($d_b(\alpha_a^{x}) \rightarrow
    r_b(\alpha_c^{y : y > x}) \rightarrow d_b(\delta_b)$), a \process
    may never receive again, hence deliver and forward a message that
    was received and discarded before ($\alpha_c^{y}$). When such a
    message contains its best up-to-date partition, a \process may
    never end up in its best partition.
    %    Therefore, \processes do not reach
    % consistent partitioning.
  \item [Purge then EFB:] Assuming the eventual and definitive removal
    of stale messages at each \process ($S(\alpha_a) \implies
    (d_b(\alpha_a) \implies \eventually d_b(\alpha_a) \rightarrow
    d_b(m') \not\rightarrow d_b(\alpha_a))$); and assuming that every
    removal eventually triggers the forwarding of best delivered
    messages ($d_c(\delta_x) \implies \eventually f_d(\alpha_y)$),
    \processes may deliver other stale messages that will be 
    eventually removed to never be delivered again. In the worst case,
    all \processes deliver and remove all stale messages to ultimately
    deliver and forward only up-to-date messages ($\eventually d_c(m')
    \implies \neg S(m')$). As in Theorem~\ref{theo:efb}, they
    eventually deliver and forward their best up-to-date message.
    
    %% upon receipt of such $\alpha_y$, either the \process already
    %% delivered its removal and it does 
    

    %% ($d_c(\delta_x) \implies \eventually f_d(\alpha_y) \wedge \neg
    %% S(\alpha_y)$)


    %% eventually every \process only delivers and forwards up-to-date
    %% messages, or no message at all 




    %% , every \process eventually delivers and forwards the best
    %% up-to-date delivered messages as in Theorem~\ref{theo:bef}.
    
    %% Removing \emph{forever} all such stale messages about
    %% deleted partitions would allow \processes to propagate their best
    %% up-to-date partition again, eventually reaching consistent
    %% partitioning together, as stated by Theorem~\ref{theo:bef}.
  \end{asparadesc}
  Using EFB$^+$, \processes reach consistent partitioning together
  even under dynamic partitioning settings where \nodes can
  \texttt{Add} and \texttt{Del}ete their partition.
\end{proof}

%% Figure removed as it's kind of redundant with preceding figure that
%% depicts the issue
%% \begin{figure} 
%%   \centering\input{input/figproofA.tex}
%%   \caption{\label{fig:proofA}Stale $\alpha$ messages may
%%       stop other $\alpha$ messages from reaching all \processes ($b$
%%       and $c$) that require it along the shortest path. Consistent
%%       partitioning requires eventual purging of stale messages (see
%%       Figure~\ref{fig:proofB}).}
%% \end{figure}

The main challenge consists in implementing a purging mechanism that
ensures the \emph{eventual and definitive} removal of stale control
information. One could guarantee consistent partitioning by always
propagating the $\delta$ messages corresponding to the $\alpha$
messages it propagated before. In Figure~\ref{fig:problem}, it means
that as soon as \Process~$b$ forwards $\alpha_a^2$, it assumes that
its neighbors \Process~$c$ and \Process~$d$ may need the notification
of removal $\delta_a$ if it exists. However, such a solution also
implies that \processes generate traffic not only related to their
current partition, but also related to partitions they belonged to in
the past. This would prove overly expensive in dynamic systems where
\processes join and leave the system, create and delete partitions, at
any time.  Instead, we propose to use the delivery order at each
\process to detect possible inconsistencies and solve them.
%% Together, \processes eventually remove all stale control information
%% (transiting messages and local states) of the system leaving room for
%% propagation of messages about up-to-date partitions.

%% \input{input/figproof.tex}

%% Figure~\ref{fig:proof} depicts the issues with staleness and message
%% orderings. In Figure~\ref{fig:proofA}, the shortest path from any
%% source to \Process $c$ is $[a, b, c]$. However, \Process $b$ still holds
%% a stale $\alpha_d^{0.5}$ without knowing. When it receives
%% $\alpha_a^1$, it discards it, for it assumes that downstream \processes
%% are more interested in $\alpha_d^{0.5}$. To reach consistent
%% partitioning, \Process $b$ first needs to purge its current partition
%% to later accept that of its current actual shortest path:
%% $\alpha_a^1$.

%% \noindent Figure~\ref{fig:proofB} shows that removing stale control
%% information is even more complex. The removal must reach all \processes
%% of the previous shortest path going from $d$ to $b''$. Label I' shows
%% the most obvious issue where \Process $e$ changed partition for a
%% better but stale $\alpha_f$. Since it can remember its previous
%% deliveries, it could still forward $\delta_d$ for the sake of
%% consistency. However, this would lead to every \process forwarding
%% every $\delta$ they ever delivered. Such protocol's overhead would
%% depend on past partitioning instead of current one. Label III shows
%% the issue when the blocking partition is already known to be stale at
%% \Process $b'$. \Process $b''$ eventually receives $\alpha_f$ from
%% $e$. However, it cannot deliver it, for it would break last win order.
%% \Process $b'$ may be in an inconsistent state. Label IV shows the
%% corollary issue: \Process $b''$ delivered a message from a \process that
%% may be inconsistent without knowing it.

\begin{theorem}[\label{theo:threephase}Three-phase purge]
  Three phases are sufficient to eventually purge the system from
  stale control information:
  \begin{inparaenum}[(i)]
  \item propagation of delete notifications,
  \item detection of possibly blocking conditions, and
  \item propagation of delete notifications that were possibly blocked.
  \end{inparaenum}
\end{theorem}

%% \begin{figure}
%%   \centering\input{input/figproofB.tex}
%%   \caption{\label{fig:proofB}Stale $\alpha$ messages may stop $\delta$
%%     messages from reaching \processes with the corresponding
%%     partition. Consistent partitioning requires that all \processes
%%     propagate $\delta$ messages as often as possible (I); detect
%%     possible inconsistencies when parents' $\alpha$ messages
%%     contradict history or state (II); notify \processes of possible
%%     inconsistencies (III).}
%% \end{figure}

\begin{proof}
  We must prove that every \process that delivered a stale $\alpha_X$
  eventually delivers a better $\alpha_Y$, or delivers a removal
  notification of $\alpha_X$.  Figure~\ref{fig:proofB} summarizes the
  issue of purging in scenarios involving concurrent operations.

  
  (i) If every \process (such as $a$) starting from the source
  delivers and forwards a removal notification $\delta_X$ when their
  last delivery is $\alpha_X$, then every such \process eventually
  delivers the removal notification $\delta_X$ except \processes (such
  as $b$) that delivered $\alpha_X$ from a \process that delivered a
  message from another partition $\alpha_Y$ since then.
  
  These exceptions eventually receive and deliver $\alpha_Y$ since
  $\alpha_Y$ is better than $\alpha_X$ through this path, except if
  they already received and delivered the removal notification of
  $P_Y$ (such as $c$). These \processes may never receive hence
  deliver $\delta_X$, and may never receive hence deliver a better
  message than $\alpha_X$. They need an additional mechanism to
  eventually purge $\alpha_X$ that cannot rely on the eventual purging
  of $P_Y$ at \processes like $b$, to avoid deadlocks.
  
  (ii) Assuming that every \process keeps an history of its past
  deliveries, \processes (such as $c$) can detect the inconsistency,
  since they receive from their parent an already deleted partition
  $P_Y$. This notification means that the parent discards any
  $\delta_Z$ with $\alpha_Z^z < \alpha_Y^y$, and most importantly, if
  $\delta_X$ exists, it discards it. To ensure the purge of stale
  messages, a detecting \process must assume the worst case that such
  $\delta_X$ exists, and send another kind of message, noted $\Delta$,
  that notify the possible removal of $P_X$.
  
  (iii) A \process (such as $d$) whose last delivery is $\alpha_X$,
  but whose parent is neither inconsistent (like $b$) nor receiving
  $\delta_X$ (like $a$), eventually receives $\Delta$ from a detecting
  \process, either directly or transitively, for such a child \process
  ($d$) trusts the possible removal of $P_X$ by delivering and
  forwarding such $\Delta$. $\Delta$ suffers from identical blocking
  conditions (between $b$ and $c$) than $\delta$, leading to the same
  solutions of detection and propagation of $\Delta$. Eventually,
  every \process whose last delivery is $\alpha_X$ receives and
  delivers either a better $\alpha_Z$, or $\delta_X$, or $\Delta_X$.
  %
  %% Some \processes may have delivered messages about other partitions
  %% before or after $\alpha_X$. \Processes such as $b$ and $c$ delivered
  %% messages about $P_Y$.  For \processes such as $b$, the last delivery
  %% is $\alpha_Y$: $d_b(\_) \rightarrow \ldots \rightarrow d_b(\alpha_X)
  %% \rightarrow \ldots \rightarrow d_b(\alpha_Y)$; For \processes such
  %% as $c$, the last delivery is $\alpha_X$, and they delivered the
  %% addition and removal of $P_Y$: $d_c(\_) \rightarrow \ldots
  %% \rightarrow d_c(\alpha_Y) \rightarrow \ldots \rightarrow
  %% d_c(\delta_Y) \rightarrow \ldots \rightarrow d_c(\alpha_X)$. Both
  %% $a$ and $d$ delivered $\alpha_X$ last: $d_a(\_) \rightarrow \ldots
  %% \rightarrow d_a(\alpha_X)$. Their difference being their position in
  %% the chain: $d$ is a child of \processes that delivered messages
  %% about $P_Y$.
  %
  %% \begin{asparadesc}
  %% \item [($a$ or $c$ or $d$) to ($a$ or $c$ or $d$):] The source is
  %%   like $a$.  By propagating from \process to \process the
  %%   corresponding $\delta_X$ message, these \processes purge
  %%   $\alpha_X$.
  %% \item [$a$ to $b$:] $b$ stops the propagation of $\delta_X$, for the
  %%   latter does not target its current partition.
  %% \item [$b$:] They need to purge their own $P_Y$, we must \TODO{prove
  %%   that $[a, b, c, d]$ is solved and that it does not require to
  %%   purge $P_Y$.}
  %% \item [$b$ to $d$:] would deliver $d_(\alpha_y)$ hence becoming $b$.
  %% \item [$b$ to $c$:] block $d_c(\alpha_y)$, so $c$ stays in $c$. But
  %%   it detects $b$ is its parent, and possibly blocked any delta with
  %%   its value $r_b(\delta_z) \rightarrow d_b(\delta_z)$. Since not
  %%   sure, $\Delta$
  %
  %% \item [\processes with $\alpha_X^x \rightarrow \alpha_Y^y$ with last
  %%   $\alpha_Y^y$, for $\alpha_Y^y< \alpha_X^x$:] \Processes such as
  %%   \Process~$b$ that do not directly suffer from the non-delivery of
  %%   $\delta_X$. They need to purge their own $P_Y$ if need
  %%   be. Nonetheless, they deliver and forward $\alpha_Y$ that at least
  %%   one following \process will receive.
  %% \item [\processes with $\delta_Y \rightarrow \alpha_X$:] \Processes
  %%   such as \Process~$c$ that do not belong to the preceding category,
  %%   for they already delivered $\delta_Y$. Nevertheless, best eventual
  %%   forwarding guarantees that they receive $\alpha_Y$, which
  %%   contradicts their history or state. In such a case, the detecting
  %%   \processes purge their own $\alpha_X$. The detecting \processes
  %%   must also notify subsequent \processes that their current
  %%   partition \emph{may be} deleted. Indeed their parent may have
  %%   blocked the corresponding $\delta$ messages and subsequent
  %%   \processes must purge their possibly stale state, for the sake of
  %%   consistency.  We note such a notification $\Delta_X$ to emphasize
  %%   their proximity to $\delta_X$ messages.
  %%   % the uncertainty of a $\delta$ message.
  %% \item [\processes with last $\alpha_X$ receiving $\Delta_X$ from
  %%   their parent:] \Processes such as \Process~$d$ that have
  %%   $\alpha_X$ but preceding delivered messages are not
  %%   important. Such \processes must trust detecting \processes by
  %%   delivering and forwarding $\Delta_X$. It is worth noting that
  %%   these messages are subject to all aforementioned blocking
  %%   conditions, but are also solved by aforementioned mechanisms.
  %% \end{asparadesc}
  %% Propagation~I terminates: a \process does not deliver a $\delta$
  %% message if it has already delivered it. Propagation~III terminates: a
  %% \process does not deliver a looping message.  
  % ; and since \processes forward the messages they deliver, upstream
  % \processes eventually receive and may deliver messages detected as
  % issue. In Figure~\ref{fig:proofB}, \Process~$e$ eventually
  % receives $\delta_f$ from \Process~$b'$.
  %% Three-phase purge ensures that all \processes of the system
  %% eventually removes stale messages, leaving room for best eventual
  %% forwarding of up-to-date messages.
  %
  %  \TODO{cannot loop add from $e$ , undo from $b'$ because $b'$ sent
  % delete to $e$, it will solve the inconsistency.}
  %
  %% In the meantime, \processes that still belong to a partition can
  %% propagate their respective last $\alpha$ message, and reach
    %% consistent partitioning.
\end{proof}



\subsection{Implementation and complexity}

Algorithm~\ref{algo:ascast} provides the few instructions of \NAME
that implement three-phase purge and eventual forwarding of best to
enable dynamic consistent partitioning. For the sake of simplicity, it
does not handle multiple sessions and associated optimisation such as
data structure sharing and message packing.

\begin{algorithm}
  \input{input/algoascast.tex}
  \caption{\label{algo:ascast}\NAME at \Process~$p$.}
\end{algorithm}

As stated in Theorem~\ref{theo:dcp}, every \process must purge stale
messages.  To identify staleness, each \process maintains a vector of
versions that associates the respective known local counter of each
known source, or has-been source. Its size increases linearly with the
number of sources that the \process has ever known, which is the
number of \processes in the system $\mathcal{O}(V)$ in the worst case.
Nevertheless, following the principles of scoped broadcast, we expect
that every \process only acknowledges a small subset of sources.
Using such a vector, every message $m$ carries its source $s$ along
with its version $c$ that we subscript $m_{s, c}$.  Each \process
delivers and forwards
\begin{inparaenum}[(i)]
\item only newest messages (see Line~\ref{line:ascast_version}) that
\item improve their best known partition (see
  Line~\ref{line:ascast_better}).
\end{inparaenum}
This vector of versions constitutes a summary of local deliveries. It
allows a \process to detect inconsistencies in message delivery: the
parent delivered a stale message (see Line~\ref{line:ascast_version}),
or the parent delivered a worse message (see
Line~\ref{line:detectA}). % This may happen in stage II of
% Figure~\ref{fig:proofB} between $b$ and $c$.

A \process ($c$) detecting an inconsistency disseminates a $\Delta$
message. Such a $\Delta$ must not modify any vector of versions since
the partition of the corresponding $\alpha$ may still exist.
Therefore, it additionally includes and maintains a path $\pi$
initialized to $\alpha$'s one. Such a $\Delta_{s, c}^{\pi}$
transitively tracks and purges $\alpha$ messages that were forwarded
by the detecting \process. The path $\pi$ also enables a quick stop of
looping messages and in turns ensures termination. However, carrying
paths in messages is costly. In the worst case, a message piggybacks
the identity of all \processes in the system. Fortunately, message
paths and \NAME synergyze well with each other, for paths tend to be
smaller as the number of sources in the system increases. Contrarily
to $\alpha$ and $\Delta$ messages, $\delta_{s, c}$ messages do not
carry a path, and are therefore more efficient. They
\begin{inparaenum}[(i)]
\item solely rely on versions to operate, and
\item use the whole dissemination graph to propagate in the system, as
  opposed to $\Delta$ that must follow the dissemination tree of the
  corresponding $\alpha$.
\end{inparaenum}

As stated in Theorem~\ref{theo:dcp}, dynamic consistent partitioning
not only requires eventual purging of stale messages, but also the
retrieval of the best up-to-date partitions.  In that regard, both
$\delta$ and $\Delta$ messages have dual use: since they already reach
the borders of their partition by design, they trigger a competition
when reaching bordering \processes (see
Line~\ref{line:ascast_compete}).
%% This simply consists in sending the
%% current partition through the communication link from which the
%% \process received the $\delta$. Upon receipt of this answer,
%% \processes act normally by propagating their changes when they
%% improve.

\begin{algorithm}
  \input{input/algoedges.tex}
  \caption{\label{algo:edges}\NAME at \Process~$p$ in dynamic networks.}
\end{algorithm}

Algorithm~\ref{algo:edges} enables dynamic consistent partitioning in
dynamic networks where \processes can join, leave, or crash at any
time. Removing a \process is equivalent to removing all its edges, and
adding a \process is equivalent to add as many edges as necessary.
Adding an edge between two \processes may only improve the shortest
path of one of these \processes. Therefore, it triggers a competition
between the two \processes only. If one or the other \process
improves, the propagation of $\alpha$ messages operates normally.
Removing an edge between two \processes may invalidate the shortest
path of one of involved \processes plus downstream \processes. As a
side effect, removing an edge may also impair the propagation of a
partition delete. To implement this behavior, \NAME uses its
implementation of $\Delta$ messages. This prove costly but enables
\NAME even in dynamic networks subject to physical partitioning.

%% \NAME guarantees dynamic consistent partitioning by making extensive
%% use of \process-to-\process communications. It requires
%% \begin{inparaenum}[(i)]
%% \item purging stale control information, hence propagating $\delta$
%%   messages; and
%% \item retrieving the closest source, hence propagating $\alpha$
%%   messages.
%% \end{inparaenum}
In terms of number of messages, in the average case, a \process $i$
chosen uniformly at random among all \processes creates a logical
partition. Its messages $\alpha_i$ spread through the network until
reaching \processes that belong to another partition closer to
them. This splits partitions in half on average. Overall, the $a^{th}$
new partition comprises \smash{$\mathcal{O}(\frac{|V|}{2^{\lfloor
      \log_2 a \rfloor}})$} \processes. This decreases every new
partition until reaching one \process per new partition: its
source. The average number of messages per \process is
\smash{$\mathcal{O}(\frac{\overline{|O|}}{2^{\lfloor \log_2 a
      \rfloor}})$}, where \smash{$\overline{|O|}$} is the average
number of neighbors per \process.
% \TODO{Multiple receipt and
% multiple
%  delivery imply more messages (receipt bounded by $|O|$ as well).}
Deleting the $a^{th}$ partition generates twice as many messages as
creating the $a^{th}$ partition: $\delta$ messages travel through the
partition, then $\alpha$ messages compete to fill the gap.  Overall,
the communication complexity shows that \NAME scales well to the
number of partitions.
%% In the
%% worst-case, every new partition includes all but one \process
%% belonging to the previous partition. The total number of messages
%% after the $a^{th}$ new partition is $\mathcal{O}(\overline{|O|}\cdot
%% a^2)$. As for the average-case, the number of messages for the
%% partition deletion is identical to the number of messages of the
%% corresponding partition creation.
%% \begin{algorithm}[h!]
%%   \input{input/algoedges.tex}
%%   \caption{\label{algo:edges}\NAME at \Process~$p$ in dynamic networks.}
%% \end{algorithm}
Next Section provides the details of our simulations that assess the
proposed implementation.



%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "../paper"
%%% ispell-local-dictionary: "english"
%%% End: 
