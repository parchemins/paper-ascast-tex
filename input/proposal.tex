
\section{Scoped broadcast}
\label{sec:scoped}

Fog infrastructures are distributed systems comprising heterogeneous
machines interconnected by communication links. We do not consider
byzantine processes.

\begin{definition}[Fog infrastructure]
  A fog infrastructure is a connected \underline{g}raph $G(V, E)$ of
  \underline{v}ertices $V$ and bidirectional \underline{e}dges $E
  \subseteq V \times V$.  A \underline{p}ath $\pi_{ij}$ from Process
  $i$ to Process $j$ is a sequence of vertices $[i, k_1, k_2, \ldots
    k_n, j]$ with $\forall m: 0\leq m \leq n, \langle \pi_{ij}[m],
  \pi_{ij}[m+1] \rangle \in E$.
\end{definition}

Processes can send messages to their neighboring processes. Processes
can reliably broadcast messages by forwarding delivered
messages~\cite{hadzilacos1994modular,nedelec2018causal,raynal2013distributed}. However,
uniform reliable broadcast states that \emph{all} correct processes
must deliver broadcast messages. This proves costly in large scale
systems comprising thousands of processes. Instead, we define
\emph{scoped broadcast} where messages reach only interested
processes, significantly reducing generated traffic.

\begin{definition}[\underline{S}coped broadcast (S-broadcast)]
  When Process $x$ scoped \underline{b}roadcasts $b_x(m)$ a
  \underline{m}essage $m$, every correct Process $y$ within a scope
  \underline{r}eceives $r_y(m)$ and \underline{d}elivers it
  $d_y(m)$. The scope depends on \underline{s}tates $\sigma$ of
  processes, \underline{m}etadata $\mu$ within received messages, and
  a \underline{p}redicate $\phi$ verified from process to process:
  $b_x(m) \wedge r_y(m) \implies \exists \pi_{xy} : \forall z \in
  \pi_{xy}, \phi(\mu_z, \sigma_z)$.
\end{definition}

This definition highlights the transitive relevance of messages and
encompasses more specific definitions of related
work~\cite{hsiao2005scoped,lue2006scoped,wang2015prodiluvian}.  A
process from Paris could scoped broadcast a message to all processes
in this city. A process from Paris could scoped broadcast a message to
all processes in this city plus neighboring cities by overloading
forwarded messages the first time they reach another city. Similarly
to reliable broadcast, scoped broadcast implementations expose
different trade-offs on space, time, and communication.

%% \begin{definition}[S-broadcast properties]
%%   S-broadcast guarantees 3 properties:
%%   \begin{inparaenum}[(i)]
%%   \item Validity: If a correct process broadcasts a message, it
%%     eventually delivers it;
%%   \item Scoped Agreement: If a process broadcasts a message, then all
%%     correct processes within the scope eventually delivers it;
%%   \item Scoped Integrity: A process delivers a message only if it was
%%     previously broadcast within the scope.
%%   \end{inparaenum}
%% \end{definition}

In this paper, we propose to dynamically adapt the scope of
S-broadcast using S-broadcast itself.  At any time, a process can
become the source of a new logical partition by transitively modifying
the respective state of neighboring processes using path weights.
When a process S-broadcasts a message in this partition, it reaches
all processes belonging to this partition. While the first partition
gathers all processes of the system, the following partitions reduce
the membership size of their neighboring partitions. In turns, the
traffic generated to adapt scopes scales with the number of
partitions.
 
\begin{definition}[Consistent partitioning]
  Let $S \subseteq V$ be the set of \underline{s}ources, $W_{xy} =
  W_{yx}$ be the symetric \underline{w}eight between $x$ and $y$,
  $\Pi_{xz}$ be the shortest \underline{p}ath from $x$ to $z$ the
  weight of which $|\Pi_{xz}|$ is lower than any other path weight,
  the consistent partitioning $\mathcal{P}$ is a set of logical
  partitions $P_{s\in S}$ such that each process belongs to a logical
  partition comprising its closest source process.  $\forall p \in
  P_{s_1}, \nexists P_{s_2}$ such that $|\Pi_{s_1p}| > |\Pi_{s_2p}|$.
\end{definition}

\input{input/figdel.tex} %% figure positioning

%% \begin{definition}[\label{def:transitivedelivery}Transitive delivery]
%%   Transitive delivery ensures the system eventually converges to
%%   optimal partitioning:
%%   \begin{inparaenum}[(i)]
%%   \item (\textbf{termination}) processes do not need to propagate
%%     operations they do not deliver: $\forall \langle i, j \rangle \in
%%     E, \neg d_i(\alpha_{s}^w)\implies \neg
%%     d_j(\alpha_{s}^{w+w_{ij}})$;
%%   \item (\textbf{propagation}) operations delivered by a process may
%%     also benefit neighbor processes: $\forall \langle i, j \rangle \in
%%     E, d_i(\alpha_{s}^{w_1}) \implies
%%     d_j(\alpha_{s}^{w_1+w_{ij}}) \vee
%%     d_j(\alpha_{*}^{w_2 < w_1 + w_{ij}})$.
%%   \end{inparaenum}
%% \end{definition}

\begin{algorithm}
  \input{input/algoadd.tex}
  \caption{\label{algo:add}Adding a partition by Process $p$.}
\end{algorithm}

Algorithm~\ref{algo:add} shows the instructions that implement
eventually consistent partitioning when weights are scalar values.  At
any time, a process running this protocol can add a logical partition
to its distributed system.  Figure~\ref{fig:add} illustrates its
behavior on a system comprising 4 processes $a$, $b$, $c$, and
$d$. Two processes $a$ and $c$ concurrently create a partition by
S-broadcasting their respective \underline{a}dd message: $\alpha_a^0$
and $\alpha_c^0$. They initialize their own state with the lowest
possible bound $0$ (see Line~\ref{line:lowestbound}), and send a
message to each of their neighbors by accumulating the corresponding
edge weight (see Line~\ref{line:accumulator}). In
Figure~\ref{fig:addC}, Process $b$ receives $\alpha_{c}^{1}$. Since it
improves its own partition distance, it keeps it and forwards it to
its neighbors. Process $b$ discards $\alpha_{b}^{1.5}$, for it does
not improve its partition distance. Processes $c$ and $d$ will never
hear of Process $a$'s partition.  In Figure~\ref{fig:addD}, processes
discard last transiting messages. The system converged to the optimal
partitioning.  Transitive relationships ensure that each process gets
its closest source while accumulation of weights ensures that messages
propagation terminates.

%% Interestingly, while the receipt order of messages does not impact on
%% local control information ($r_b(\alpha_a^{1.5}) \cdot
%% r_b(\alpha_a^{1}) \Leftrightarrow r_b(\alpha_a^{1}) \cdot
%% r_b(\alpha_a^{1.5}) \implies \TODO{d_b(\alpha_a^{1})}$), it impacts on
%% control information broadcast in the network ($r_b(\alpha_a^{1.5})
%% \cdot r_b(\alpha_a^{1}) \implies b_b(\alpha_{b}^{1.5}) \cdot
%% b_b(\alpha_{b}^{1})$ while $r_b(\alpha_a^{1}) \cdot
%% r_b(\alpha_a^{1.5}) \implies b_b(\alpha_a^{1})$).

While only adding logical partitions to the distributed system is
straightforward, removing them introduces additional complexity. 





\section{Adaptive scoped broadcast}
\label{sec:adaptive}

In this section, we introduce \NAME, a wait-free reactive protocol for
logical partitioning in dynamic distributed systems the cost of which
actually depends on its usage: When the system becomes quiescent,
processes eventually converge to their respective partition and do not
require further communication afterward.

Each process is stateless, works autonomously and asynchronously, in a
peer-to-peer fashion. Each process broadcasts each change to its
neighborhood, for the state of its neighbors may depend on this change
as well. Yet, generated traffic remains \TODO{low} using scoped
broadcast. Messages that carry changes travel through the network
depending on partition of processes, stopping as soon as they
encounter uninterested processes. We demonstrate that \NAME guarantees
consistent partitioning despite different order in message deliveries
from one process to another.

This section starts by describing \NAME's functioning by detailing its
operation to avoid inconsistent states due to ordering and staleness
of delivered messages. This section ends with a complexity analysis of
proposed protocols.



%% \subsection{Intra-autonomous system partitioning}

\begin{algorithm}
  \input{input/algoadddelundo.tex}
  \caption{\label{algo:adddelundo}Dynamic partitioning by Process $p$.}
\end{algorithm}

\input{input/figproof.tex}

%% In this section, we aim at solving Problem Statement~\ref{prob:intra}
%% by proposing \NAME, a reactive logical partitioning protocol for
%% dynamic partitioning in dynamic networks.

\paragraph{Dynamic partitions.}
At any time, a process can become a source, hence adding a new
partition to the system. This partition eventually includes all
processes that are closer from this new source than any other else. We
described such protocol in Section~\ref{sec:scoped}. Processes
naturally converge towards their respective best partition by only
piggybacking a monotonically increasing distance in forwarded
messages. % \TODO{Traffic of each partition is contained to the
%  partition.}

Then, at any time, a source can revoke its self-appointed status of
source, hence deleting its partition from the system. All processes
that belong to this partition must eventually choose another partition
to belong to. Since the number of partitions does not monotonically
increase in the system any longer, each process requires a vector of
versions that monotonically increases over delivered operations.

This allows processes to quickly discard stale messages saving
bandwidth. For instance, a process that received a message originated
at Process $a$ with a version $2$ knows that any message originated at
Process $a$ with a version $1$ are stale system-wide; it must not
forward it. As consequence, this also ensure termination, for
corresponding add and delete messages cannot follow each other in
infinite loops.
% In terms of traffic, this only requires each message
% to piggyback a source identifier and version number.

\noindent Deletes must trigger competition amongst neighboring
partitions. These \TODO{add} messages operate normally and fill gaps
left open by deletes. 

\TODO{Paths and \NAME synergize well, for paths tend to be smaller as the
number of sources increase in the system.}



\paragraph{Dynamic networks.}
Adding new communication links to the network may create shortcuts
between processes. Both processes must send their current best
partition to each other. Upon receipt, they act normally: if a process
finds out that the received partition is closer than its current one,
it delivers it which in turns also triggers another competition
amongst neighbors due to forwarding.

\noindent Joining the network is equivalent to add as many
communication links as necessary between the joining process and its
new neighbors.

\begin{algorithm}
  \input{input/algoedges.tex}
  \caption{\label{algo:edges}Dynamic partitioning by Process $p$ in dynamic networks.}
\end{algorithm}

When removing a communication link between two processes does not
break any active path, because neither distances of processes depend
on the other, then nothing needs to be done. \NAME has no overhead.
Unfortunately, when a process' distance depends on the other process,
the protocol becomes much more complex. Indeed, this requires to
\TODO{undo} all add messages originated from this process. A message
must convey the fact that
\begin{inparaenum}[(i)]
\item an edge at a particular process has been removed, and
\item the distance that has been delivered by a process comes from
  this particular process.
\end{inparaenum}

\noindent \NAME handles this as a particular case of partition within
current partition: it contains to affected regions the traffic
generated to patch affected regions. In order to know if it is
affected by the \TODO{undo} operation, using distances already
piggybacked in messages is not sufficient.  Each process must know the
path taken by delivered message. Since we do not beforehand which
communication links will crash and which messages will be affected by
undos, each message has to carry its path along forwarding. This also
allows processes to remove loops, for they cannot rely on version
number (that remains unchanged) for this operation.

\noindent Instead of version number, one could use such paths to remove loops
due to \TODO{add and del}, however this may be much more costly in
terms of generated traffic. Version numbers guarantee that only one
delete is delivered and all prior inserts are then discarded, while
using paths, processes may deliver multiple inserts and deletes before
reaching termination. \TODO{maybe clearer with figures.} As
consequence, \NAME still makes use of vector of versions.

\noindent Although costly, piggybacking paths with logical partitioning synergies
well, for the size of these paths decreases quickly as the number of
partitions grows.



\paragraph{A last optimization.}
\NAME makes extensive use of paths to enable deleting messages without
incrementing local counters. Messages carry their respective path and
processes detect when such messages have been looping when they carry
their identity (see Lines~\ref{line:notloopingA} and
\ref{line:notloopingB} of Algorithm~\ref{algo:adddelundo}). Since
membership is all that matters, we propose to trade vectors of
identities for Bloom filters~\cite{almeida2007scalable} to improve on
generated traffic and
anonymity~\cite{whitaker2002forwarding}. Processes know with high
probability if they already received and forwarded each message
without knowing the identity of all processes that received it.  False
positive probability only incurs premature stopping of broadcast
messages and does not invalidate the delete of specific messages.



%% \subsection{Inter-autonomous system partitioning}

%% \begin{figure}
%%   \centering\input{input/figAS.tex}
%%   \caption{\label{fig:AS}Inter autonomous systems
%%     partitioning. \TODO{More about relative ordering of links at each
%%       process}}
%% \end{figure}

%% In this section, we aim at solving Problem Statement~\ref{prob:inter}
%% by proposing \NAMEB, an extension of \NAME, that enables dynamic
%% logical partitioning in inter-autonomous systems. It leverages
%% hierarchical properties of these networks to further improve on scoped
%% flooding.

%% Autonomous systems are geo-distributed networks. Heterogeneous
%% communication links. Hierarchy of communication links. Per-object
%% broadcast.

%% We leave the link handling to membership protocols~\REF. The ordering
%% of links can be done based on latency. For instance, from 0 to 100 ms,
%% rank 0, from 100 to 1s, rank 2 \ldots

%% \begin{algorithm}
%%   \input{input/algoaaaa.tex}
%%   \caption{\label{algo:aaaa}\NAMEB running at Process $p$ for dynamic
%%     partitioning in inter-autonomous systems.}
%% \end{algorithm}

%% Figure~\ref{fig:AS} shows an example of inter-AS logical partitioning
%% where each process ranks its communication links, and each process
%% forwards messages to its neighbors starting from the rank of the link
%% that triggered the receipt, to its highest rank neighbors. In this
%% example, Process $e$ adds a partition. It forwards the generated
%% message to all its neighbors as if it received it from its lowest rank
%% links. When Process $a$ receives $\alpha_e^1$ from its rank-$0$ link,
%% it forwards it to rank-$0$ links and rank-$1$ links.  Process $b$
%% stops the propagation, for all its links have lower ranks than the one
%% from which it received the message $\alpha_e^2$. Ultimately, the
%% partition includes Process $e$, Process $a$, and Process $b$. Process
%% $c$ and Process $d$ remain unaware of the new \TODO{object}.

%% To ease the reasoning about inter-AS dynamic partitioning in dynamic
%% networks, \NAME runs an independent broadcast protocol for each
%% object, and for each rank of links.  \TODO{Not so easy\ldots}
%% \TODO{Write and describe algo.} \TODO{Overhead of separating things,
%%   slightly more memory, but traffic wise? slower ?}  \TODO{In the
%%   example, not only Process $b$ keeps $e_1$ as its best partition, but
%%   it keeps it for links of rank 0, and links of rank 1.}  When there
%% are no ranking in links, processes solely rely on
%% Algorithm~\ref{algo:adddelundo} for optimal partitioning.





\section{Complexity}
\label{sec:complexity}

\TODO{To rework, for there are more components now. Maybe do this
  along the description of the approach.}

We focus on average-case and worst-case complexity. We divide our
analysis into space, time, and communication complexity.

\textbf{The communication complexity} concerns the size and number of
messages required to reach optimal partitioning. In the average-case,
a process $i$ chosen uniformly at random among all processes creates a
logical partition. Its messages $\alpha_i$ propagate through the
network until reaching processes that belong to another partition
closer to them. This splits partitions in half in average. Overall,
the $a^{th}$ new partition comprises
\smash{$\mathcal{O}(\frac{|V|}{2^{\lfloor \log_2 a \rfloor}})$}
processes. This decreases every new partition until reaching $0$
processes per new partition: even the chosen process already belongs
to its optimal partition. The average number of messages per process
is \smash{$\mathcal{O}(\frac{\overline{|O|}}{2^{\lfloor \log_2 a
      \rfloor}})$}. \TODO{Multiple receipt and multiple delivery imply
  more messages (receipt bounded by $|O|$ as well).} Deleting the
$a^{th}$ partition generates the exact same number of messages than
the $a^{th}$ partition creation. \TODO{But what about echos?} In the
worst-case, every new partition includes all but one process belonging
to the previous partition. The total number of messages after the
$a^{th}$ new partition is $\mathcal{O}(\overline{|O|}\cdot a^2)$. As
for the average-case, the number of messages for the partition
deletion is identical to the number of messages of the corresponding
partition creation.

%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "../paper"
%%% ispell-local-dictionary: "english"
%%% End: 
