
\newcommand{\FIGSCALE}{0.99}

\section{Experimentation}
\label{sec:experimentation}

%% This section describes the results of our experimentation evaluating
%% the properties of \NAME that enables adaptive scoped broadcast in
%% dynamic networks.

%% \TODO{Each \process has a space complexity of $\mathcal{O}(\log_2(d \cdot
%% |V|))$, and generates messages of identical space complexity. In terms
%% of number messages, in the average case, a \process $x$ chosen
%% uniformly at random among all \processes creates a logical
%% partition. Its messages $\alpha_x$ spread through the network until
%% reaching \processes that belong to another partition closer to
%% them. This splits partitions in half on average. Overall, the $n^{th}$
%% new partition comprises \smash{$\mathcal{O}(\frac{|V|}{2^{\lfloor
%%       \log_2 n \rfloor}})$} \processes. This decreases every new
%% partition until reaching one \process per new partition: its
%% source. The average number of messages per \process is
%% \smash{$\mathcal{O}(\frac{\overline{|O|}}{2^{\lfloor \log_2 n
%%       \rfloor}})$}, where \smash{$\overline{|O|}$} is the average
%% number of neighbors per \process.}
%% \TODO{\TODO{Multiple receipt and multiple delivery} In terms of number of
%% messages, deleting the $a^{th}$ partition generates twice as many
%% messages as creating the $a^{th}$ partition: $\delta$ messages travel
%% through the partition, then $\alpha$ messages compete to fill the gap
%% \TODO{which is?}. \TODO{What about false positives?} Overall, the
%% communication complexity shows that \NAME scales well to the number of
%% partitions.}

%% In the
%% worst-case, every new partition includes all but one \process
%% belonging to the previous partition. The total number of messages
%% after the $a^{th}$ new partition is $\mathcal{O}(\overline{|O|}\cdot
%% a^2)$. As for the average-case, the number of messages for the
%% partition deletion is identical to the number of messages of the
%% corresponding partition creation.


This section aims to answer the following questions about \NAME: What
is the overhead of reaching consistent partitioning using \NAME in
large scale networks?  Is \NAME relevant in Edge infrastructures where
\processes are geo-distributed into clusters? We performed the
experimentation using PeerSim, a simulator written in Java that allows
researchers to evaluate and assess distributed algorithms in large
scale networks~\cite{montresor2009peersim}. The code is available on
the Github platform at
\TODO{\url{https://anonymous.4open.science/r/peersim-partition-5592}}.

%% \subsection{Confirm the complexity analysis stating that
%%   communication and time overheads depend on the current partitioning
%%   of the system.}

\begin{asparadesc}
\item [Objective:] Confirm the scalability of \NAME by higlighting the
  trade-off between the current partitioning of the system and the
  protocol's overhead in terms of traffic and termination time.
  
\item [Description:]
  
We build a network comprising 10k \processes. First, we chain
\processes together, then we add another communication link per
\process to another random \process. Since links are bidirectional,
each \process has 4 communication links on average. We set the latency
of links between 20 and 40 ms at random following a uniform
distribution. We set the weight of links between 5 and 15 at random
following a uniform distribution. Weights and latency are different,
hence the first $\alpha$ received by a \process may not be that of its
shortest path. It implies more concurrent operations, hence more
traffic to reach consistent partitioning.

\noindent We evaluate dynamic consistent partitioning. First, we
create 100 partitions one at a time: \processes reach consistent
partitioning before we create each new partition. Second, we remove
every partition one at a time, in the order of their creation, hence
starting from the first and oldest partition that had been added.

\noindent We focus on the complexity of \NAME. We measure the average
number of messages generated per \process per second during the
experiment; and the time before reaching consistent partitioning after
adding or removing a partition.

\begin{figure}
  \centering\includegraphics[width=\FIGSCALE\columnwidth]{img/as_cast_complexity.eps}
  \caption{\label{fig:complexity}Overhead of dynamic consistent partitioning
    using \NAME.}
  
  %% \caption{\label{fig:complexity}Cumulative average number of messages
  %%   per process in a network comprising 10k processes; along with the
  %%   duration before reaching consistent partitioning after adding or
  %%   removing a partition, totaling 100 new partition then removed.}
\end{figure}

\item [Results:]

Figure~\ref{fig:complexity} shows the results of this experiment. The
top part shows the average traffic per \process per second divided
between $\alpha$ and $\delta$ messages. The bottom part shows the time
before reaching consistent partitioning.

\noindent Figure~\ref{fig:complexity} confirms that \NAME's overhead
depends on the size of partitions. In this scenario, it empirically
corresponds to a complexity in terms of number of messages of
$\mathcal{O}(\frac{|E|}{|V|\cdot|P|})$ where $E$ is the number of
links, $V$ is the number of \processes, and $P$ is the number of
partitions. In other terms, the $p^{th}$ partition contains $1/p$
\processes and reduces the size of closest partitions so every
partition has $1/p$ \processes on average.
  
\noindent Therefore, the first partition is the most expensive, for $\alpha$'s
must reach every \process which takes time and generate more traffic.
\NAME quickly converges towards consistent partitioning in only 350
milliseconds. The last and $100^{th}$ partition added around 21
seconds is the least expensive. By using scoped broadcast, control
information only reaches a small subset of the whole network.

\noindent Figure~\ref{fig:complexity} also confirms that \NAME's
delete operations are more expensive than add operations. Indeed, the
top part of the figure shows that after 21 seconds, when the
experiment involves removals, traffic includes both $\alpha$'s and
$\delta$'s. The latter aims at removing stale information and
triggering competition while the former aims at updating shortest
paths. As corollary, the convergence time increases, for $\delta$
messages must reach the partition borders before sound competitors
propagate their partition. It is worth noting that this delete
operation involves concurrency: removals still propagate while
the competition has started. %%is already partially triggered and propagating.

%% \begin{figure*}
%%   \begin{center}
%%     \subfloat[Part A][\label{fig:complexity}Overhead of consistent partitioning
%%       using \NAME]
%%              {\includegraphics[width=0.5\columnwidth]{img/as_cast_complexity.eps}}
%%              \hfill
%%     \subfloat[Part B][\label{fig:geant}Overhead of \NAME in the partitioning of 2 clusters.]
%%              {\includegraphics[width=0.5\columnwidth]{img/as_cast_geant.eps}}
%%   \end{center}
%% \end{figure*}


\noindent Figure~\ref{fig:complexity} shows that the overhead of
adding the $1^{st}$ partition does not correspond to the overhead of
deleting this $1^{st}$ partition. When adding it, messages must reach
all \processes while when removing it, messages must reach a small
subset of this membership.  \NAME's overhead actually depends on
current partitioning as opposed to past partitionings.

\noindent Finally, Figure~\ref{fig:complexity} highlights that after
49 seconds, i.e., after the 100 adds and the 100 deletes, \processes
do not generate traffic anymore. Being reactive, \NAME has no overhead
when there is no operation in the system. \NAME's overhead actually
depends on its usage.

\end{asparadesc}

%% \subsection{Distribution and hotspots}

%% \subsection{Confirm that \NAME locks down the traffic of decentralized content
%%   indexing in the context of dynamic inter-autonomous system
%%   communications.}

\begin{asparadesc}

\begin{figure}
  \centering\includegraphics[width=\FIGSCALE\columnwidth]{img/as_cast_geant.eps}
  \caption{\label{fig:geant}Overhead of \NAME in the partitioning of 2 clusters connected by a long distance link.}
\end{figure}

  
\item [Objective:] Confirm that \NAME locks down the traffic of decentralized content
  indexing in the context of dynamic inter-autonomous system
  communications.
  
\item [Description:]

We build a network by duplicating the G{\'E}ANT
topology~\cite{knight2011internet} -- a real infrastructure spanning
across Europe -- and by connecting these two clusters with a high
latency link: $200$ ms simulating cross-continental communications
such as Europe-America. The experiments comprise $2 \times 271 = 542$
\processes and we derive intra-cluster latency from their \processes'
geographic location.

\noindent We evaluate the traffic of \NAME by measuring the average
number of messages per \process over the experiments. In the first
experiment, at $50$~ms, only one \process becomes source, hence there
is only one partition for the whole distributed system. In the second
experiment, at $50$~ms, two \processes become sources, one per
cluster. Afterwards both scenarios are identical. At $850$~ms, we
remove the link between the two clusters. At $1.7$~s, we insert back this
link.


\begin{figure*}
  \subfloat {
    \includegraphics[width=\FIGSCALE\columnwidth]{img/europe-ases.pdf}
  }
  \hspace{5pt}
  \subfloat {
    \centering\includegraphics[width=\FIGSCALE\columnwidth]{img/europe_as_vs_xas.eps}
  }
  \caption{\label{fig:europe-ases}Traffic overhead and indexes
    maintained by \NAME and its extension \NAMEC in an Edge
    infrastructure comprising 40 interconnected autonomous systems of
    1157 \processes spanning across Europe~\cite{knight2011internet}}
\end{figure*}



\item [Results:]

Figure~\ref{fig:geant} shows the results of this experimentation. The
top part displays the results with one source while the bottom part
displays the results with one source per cluster.

\noindent Figure~\ref{fig:geant} confirms that concurrent
\texttt{Add}s may reach consistent partitioning faster. In particular,
the top part of Figure~\ref{fig:geant} depicts a slow down in traffic
around $500$ ms due to the high latency inter-continental link. The
first plateau shows the source's autonomous system acknowledging this
source, while the second shows the other autonomous system catching
up.  The inter-continental link is a bottleneck that does not exist
when each cluster has its own source.

\noindent Figure~\ref{fig:geant} highlights that removing the
inter-continental link generates additional traffic. The cluster cut
off from the source must purge all control information about this
source.  Most importantly, Figure~\ref{fig:geant} shows that \NAME
still operates well when \emph{physical} partitions appear. \Processes
from the cluster without source do not belong to any partition while
\processes from the other cluster belong to the same partition. 

\noindent Figure~\ref{fig:geant} shows that, when adding back the
inter-continental link, the two clusters can communicate again. In the
experiment involving one source for two clusters, it generates
traffic. After a $200$ milliseconds delay corresponding to the link
latency, the cut off cluster starts to communicate $\alpha$ messages
again. Eventually, all \processes belong to the same
partition. However, in the experiment involving one source \emph{per}
cluster, the new link does not trigger noticeable traffic, for
\processes already know their closest source located in their cluster.

\end{asparadesc}

\begin{asparadesc}
  \item[Objective:] Highlight the shortcoming of \NAME in Edge
    infrastructures and propose an improvement called \NAMEC (stands
    for \underline{cross} \underline{\NAME}) that fits this context by
    enabling lazy dynamic partitioning.
    
  \item[Description:] We build a network of networks by using an Edge
    infrastructure comprising 1157 \processes distributed in 40
    interconnected autonomous systems spanning across
    Europe~\cite{knight2011internet} as depicted in the left
    Figure~\ref{fig:europe-ases}. \emph{Gateway} \processes (dark in
    the figure) link autonomous systems together, \eg a Lisbon \node
    links Portugal to Spain and United Kingdoms through a Madrid \node
    and a London \node respectively.

    \noindent The left Figure~\ref{fig:europe-ases} depicts the
    operations executed during the simulation that lasts 7 seconds: at
    1 second, a \node located in Lisbon, Portugal performs an
    \texttt{Add}; at 2 seconds, a \node located in Palma de Majorque,
    Spain performs an \texttt{Add}; at 3 seconds, a \node located in
    Paris, France performs an \texttt{Add}; at 4 seconds, a \node
    located in Hvanneyri, Iceland performs an \texttt{Add}; and
    finally, at 5 seconds, the \node in Spain performs a \texttt{Del}.
    
    \noindent \NAMEC extends \NAME to enable lazy dynamic partitioning
    by allowing gateways to stop notifications when their respective
    network does not appear to have a source. Using \NAMEC, each
    \process maintains a \emph{local} index that corresponds to the
    best partition of its autonomous systems, and a \emph{global}
    index that corresponds to the best partition cross autonomous
    systems, \ie adjacent autonomous systems that have at least one
    source.
    
    \noindent We measure the number of messages transiting through the
    network for each operation, and we measure the number of
    \processes that index (\ie belong to a partition) over time.
    
  \item[Results:] Figure~\ref{fig:europe-ases} shows the results
    of this experiment. The top part highlights the cost of each
    partitioning protocol after each operation, while the bottom part
    provides the insight that explains these costs by displaying the
    number of indexes maintained by each protocol.

    \noindent Figure~\ref{fig:europe-ases} shows that Portugal's
    \texttt{Add} costs an order of magnitude more with \NAME compared
    to \NAMEC.  \NAME's messages propagate through all Europe, for
    \NAME regards Europe as 1 network of 1157 \processes while
    \NAMEC's messages propagate through Portugal's network of 23
    \processes only.

    \noindent Figure~\ref{fig:europe-ases} shows that Spain's
    \texttt{Add} costs slightly more with \NAMEC compared to \NAME.  A
    \process in Madrid links Portugal to Spain and the rest of
    Europe. Since Lisbon is closer to Madrid than Palma de Majorque
    is, only 11 \processes in Spain actually need to receive and
    deliver the new notification, hence the small overhead of this
    operation with \NAME. Using \NAMEC, the overhead is slightly
    higher since
    \begin{inparaenum}[(i)]
    \item the 20 \processes of Spain's network need to receive and
      deliver the new notification, \emph{and}
    \item Madrid's \process echoes Lisbon's notification as soon as it
      receives Palma's notification to 11 \processes.
    \end{inparaenum}

    \noindent Figure~\ref{fig:europe-ases} highlights the worst
    case scenario of \NAME: the cost of France's \texttt{Add} is close
    to that of Portugal's \texttt{Add} since it updates the whole
    Europe excluding Portugal and Spain. On the opposite, \NAMEC only
    updates France's 39 \processes.

    \noindent Figure~\ref{fig:europe-ases} shows that Iceland's
    \texttt{Add} has similar cost for \NAME and \NAMEC. Indeed, they
    both update Iceland, and when the notifications reach Copenhagen
    in Danemark, they stop either because France's notifications are
    closer (\NAME) or the Danish network does not have any source
    (\NAMEC).

    \noindent Finally, Figure~\ref{fig:europe-ases} shows that
    Spain's \texttt{Del} have similar cost for \NAME and
    \NAMEC. Nevertheless, the trade-off is different: \NAME's overhead
    comes from the 11 \nodes that need to acknowledge staleness and
    deliver the echos from Portugal; \NAMEC's overhead comes from the
    20 \nodes that need to acknowledge staleness. Using \NAMEC,
    Spain's network does not propagate echos since it does not have
    any source anymore.

\end{asparadesc}

%% \begin{asparadesc}
%%   \item[\TODO{Overall:}] this experimentation empirically demonstrates the
%%     benefits of \NAME in the context of geo-distributed
%%     infrastructures, e.g., inter-connected autonomous systems where
%%     \processes and communications links may be added and removed at
%%     any time. \NAME coupled with replication strategies designed for
%%     Edge infrastructures would allow locking down the traffic of
%%     replica indexing, while providing every \process with quick access
%%     to replicated content.
%% \end{asparadesc}

\TODO{Overall + transition.}


%% Next Section reviews state-of-the-art approaches for content indexing
%%  in geo-distributed infrastructures and explains their shortcomings.

%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "../paper"
%%% ispell-local-dictionary: "english"
%%% End: 
