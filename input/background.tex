
\section{Related Work and Motivation}
\label{sec:background}

%\TODO{More related work. More motivations etc. Maybe describe IPFS?}
This section reviews the existing solutions to locate a given content in a network and details the limitations 
of such solutions in a Fog context. 
We first present the related work on content localization at the system level, either with centralized or distributed approaches. 
We then focus on message-passing solutions and explain why well-known existing software middlewares such as broadcast, or gossip protocols are not good candidates in their existing implementations. 
Finally, we provide the intuition that motivated the design of our protocol.

\subsection*{Content indexing}
In the context of this paper, an \textit{ideal} content indexing service would enable that for any content, every node would be able to access its closest replica.
Basically, offering such a service would require (i) to have access to the list, namely the \textit{index}, of current replica localizations, (ii) to be aware of the topology to compute which replica is the closest for a given location.


(i) Deploying a centralized server that maintain an index of all replica localizations has been proposed~\cite{fogstore, p2p-alto, p2p-oracle, snamp}. However, this solution suffers from well-known disadvantages inherent to centralized solutions (load balancing, robustness, locality, etc.) that are even magnified in a Fog context.
Distributing this index among nodes in the network circumvent some of these issues, either using coordinate-based overlays~\cite{coin_19, voronet} or Distributed Hash Tables~\cite{squirrel, ipfs, dht-name-resolution, mdht} for example. In the latter, each node stores a part of the index, defined by an interval between hash values. 
Before downloading any object, a node first
hashes the content to obtain the address of the node that stores the replica localizations of this given object. After obtaining from the remote node the list of available replicas, it can select the closest copy to download from. We emphasize that, in this setting, the DHT only stores information about replicas localizations, not the content itself. DHT-based approaches are well-studied and easy to deploy in order to offer such a localization service. 


(ii) Being centralized or distributed, this index should be enhanced with the topology knowledge in order to be able to decide where resides the closest replica . Maintaining a consistent view of an ever changing topology accross a network is ihnerently complicated, especially in asynchronous settings. This is a well-studied problem in the network community and numerous protocols have been proposed. As for the index, this knowledge about the topology can be either centralized[REF] or distributed[REF].

%However, solutions that require to contact a remote node (either a server or a DHT node) to request this index usually violate the locality property. In other words, a request about a given object localization may travel far away in the network even if this object is actually close to the requester. 
%Moreover, they incur a lookup penalty that increases the time to actually get the object. In fact, the lookup delay can sometimes be larger than downloading the object itself, especially for smaller objects, as already observed in~\cite{confais2017performance}. Finally, this may prevent accessing objects when network partitons occur, even if they are still accessible.


\subsection*{Index dissemination}
In this paper, we advocate that in the Fog context, content should be accessible without having to request any remote node. 
To do so, another approach consists in disseminating this information accross the network.
Broadcasting information about cache updates to all nodes in the system is a straightforward way to maintain consistent information about replica localization for all nodes~\cite{nlsr,lscr}. Indeed, having the entire knowledge of all the replica localizations along with distance information carried into messages, each node can easily compute where the closest copy of a given object resides, without contacting any remote node. Moreover, removing the lookup latency directly involves faster downloading times. 
Multiple broadcast protocols have been designed to cope with various requirements.
One could also solve this issue by using a conflict-free replicated datantype (CRDT) for set data structures~\cite{shapiro2011crdts}. 
However, either by broadcasting or with CRDTs, both inherently imply that every nodes will eventually receive all messages. 
That means information that might only interests a small subset of nodes is actually spread out all over the network. This is in contradiction with the locality property we mentionned above.

Gossip protocols are also appealing candidates to disseminate information reliably across a network~\cite{epidemic-protocol}. Numerous studies have shown how quickly they converge despite high level of churn and/or failures~\cite{lpbcast}.
These protocols usually relies on a so-called \textit{peer-sampling service}~\cite{jelasity2007gossip} to efficiently propagate the information. This implies that nodes will exchange messages with random nodes in the system that can be physically far away thus violating the locality property once again. 


\subsection*{Logical partitioning}
To provide the intuition underlying our proposal, and ease the comparison with other related works, we now describe the problem tackled by this paper at an abstract level. 
Recall that for any content, every node would be able to access its closest replica \textbf{without any prior request}.
Suppose there exists an oracle in the system that instantly knows the arrival/departure of nodes in the topology, and the location of the creation/removal of replicas. In other words, this oracle is constantly aware of the current topology and the current list of all available replicas of a given content in the system. Equipped with these two information, it is then trivial for this oracle to compute for each node, where resides its closest replica for a given content. Mapping each node of the topology to a single replica amounts to partition the set of all nodes into $k$ disjoint sets (or partitions), where $k$ is the number of current replicas and every node in the same partition would get the content from the same replica. Interestingly, this partitioning matches the physical topology as neighbors physically closed in the infrastructure will most likely reside in the same partition.
For any event such as an arrival/departure of nodes or creation/removal of replicas, the oracle is thus able to inform the \textit{exact} subset of nodes that has to update their location (\ie the exact scope of an event). 
The challenge of implementing such a partitioning in an asynchronous network resides in informing this same subset of nodes (or as close as possible), without any \textit{a priori} knowledge, contrary to the omniscient oracle.


\subsection*{Overlays and membership protocols}
At first glance, membership protocols as proposed in~\cite{t-man} would appear to provide suitable abstractions to create such a partioning. Yet, such protocols usually rely on peer sampling, thus same locality problem.
Moreover, membership protocols are designed to generate logical overlays by modifying the neighboring of a given node according to a given metric. 
On the contrary, we do not aim at building any overlay, as we only rely on the physical topology so the neighbors of a given node are not continusously modifed. 
Lastly, these protocols are usually cycle-based, meaning that they impose a constant load on the network traffic, even when the system state does not change.

\subsection*{Consistency}
Finally, we emphasize that consistency is at the core of \NAME. some blabla..

To avoid flooding, authors in~\cite{opnl} propose to propagate information about cache updates only towards the source. This enables for a request to be caught \textit{on-path} to the source, and be redirected to the closest replica. However, the announcement is only performed towards the source, that is requests can miss closer replicas that are not on the path to the source, thus decreasing the efficiency of the cache sharing mechanism. On the contrary, \NAME ensures that eventually all 

One could also solve this issue by removing partitions that were not advertised for a defined time~\cite{hemmati2015namebased, garcia-lopez}. \TODO{check distance-vector protocols.} 
However, relying on physical timeout could lead to either premature removals of partitions when they are still operating; or slow convergence where processes believe they belong to a partition that was removed (\TODO{plot ?}). In addition, since timeouts imply a
continuous maintenance of partitions, such partitioning protocol
incurs an overhead even in quiet contexts without dynamic partitions.


% AVK
% t-man: T-Man: Gossip-Based Overlay Topology Management5doat a random time 
% at a random time once in eachconsecutive interval of T time unit
% This buffer contains a random sample of the nodes from the entirenetwork. It is provided by apeer sampling service
% 
% We do not try to to create a topology aware overlay ! Because locality.
% We do not provide routing ! routing is two determine path between any pair of nodes. We only provide path to objects 
% 
% Koala locality aware routing. Long links. Lazzy (nothing happens)
% Koala  shares  many  core  aspectswith similar overlays, such as Chord and Symphony.
% 
% VoroNet: overlay and routing. i.e. long links 
% It links application objects rathen than physical nodes so that objects with similar characteristic are neighbors. 
% are logigal overlay, that are not correlated to the physical infrstructure. 
% Usually rely on long links...
% AVK

%% \begin{definition}[Dynamic optimal partitioning]
%%   A dynamic optimal partitioning is an optimal partitioning where the
%%   set of sources $S$ does not monotonically increase. We suffix this
%%   set with \underline{t}ime $t$ : $S(t)$.  Process $i$ joins the set
%%   of sources by \underline{a}dding its partition with messages
%%   $\alpha_i^{0}$: $Add(i \not\in S(t)) \implies i \in S(t+1)$; and
%%   leaves the set of sources by \underline{d}eleting its partition with
%%   messages $\delta_i$: $Del(i \in S(t)) \implies i \not\in S(t+1)$.
%% \end{definition}

%% Unfortunately, due to differences in receipt order of messages between
%% processes, stale information may stop prematurely the propagation of
%% relevant messages leading to inconsistent partitioning.
%% \TODO{Figure~\ref{fig:del} shows that.}
% 
% One could solve this issue by using a conflict-free replicated data
% type (CRDT) for set data structures~\cite{shapiro2011crdts}. CRDTs
% require eventual delivery of messages to ensure convergence. All
% processes need to receive, deliver, hence broadcast all
% operations. Some processes may receive operations unnecessary to their
% correct functioning, for these operations did not happen in their
% locality.  One could also solve this issue by removing partitions that
% were not advertised for a defined
% time~\cite{hemmati2015namebased}. \TODO{check distance-vector
%   protocols.} However, relying on physical timeout could lead to
% either premature removals of partitions when they are still operating;
% or slow convergence where processes believe they belong to a partition
% that was removed (\TODO{plot ?}). In addition, since timeouts imply a
% continuous maintenance of partitions, such partitioning protocol
% incurs an overhead even in quiet contexts without dynamic partitions.

%% \begin{problem}[\label{prob:intra}Consistent partitioning]
%%   How to enable \emph{consistent} dynamic optimal partitioning in
%%   dynamic network using scoped flooding?
%% \end{problem}

% \TODO{Dynamic Multiple-sources All-destinations shortest path on
%  dynamic graphs?}

%% \begin{figure}
%%   \begin{center}
%%     \input{input/figASmotivation.tex}
%%     \caption{\label{fig:ASmotivation}Scoped flooding extended to
%%       objects, processes do not know about all partitions that exist
%%       in the whole distributed system.}
%%   \end{center}
%% \end{figure}

%% To further improve scoped flooding in autonomous systems, processes
%% may belong to multiple partitions representing the objects they are
%% aware of. Figure~\ref{fig:ASmotivation} highlights the geo-distributed
%% nature of autonomous systems. Autonomous systems have topological
%% properties~\cite{nur2018geography} that processes can leverage to
%% avoid flooding the whole systems with control information about all
%% partitions. In Figure~\ref{fig:ASmotivation}, Process $e$ creates a
%% partition about a specific object, flooding Paris's AS to notify
%% neighboring processes of the object. However, it does not flood the
%% whole network, for control information stops at Process $b$. It
%% significantly saves bandwidth compared to broadcast since processes
%% below entrypoints of autonomous systems are order of magnitude more
%% numerous. Yet, Processes $c$ and $d$ know whom to ask when they need
%% to return an object they are unaware of. Processes remain efficient in
%% answering requests. \TODO{which is important for end users \REF.}

%% \begin{definition}[Partitions in asynchronous systems]
%%   Processes may hold multiple partitions \TODO{Use $\mathcal{P}$}
%%   \TODO{TODO} \TODO{or multi-partitioning?}
%% \end{definition}

%% \begin{problem}[\label{prob:inter}Inter-AS consistent partitioning]
%%   How to enable scoped flooding of objects in autonomous systems?
%% \end{problem}

%% Next Section presents our approach that solves these scientific
%% problems by relying on logical control information only.

%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "../paper"
%%% ispell-local-dictionary: "english"
%%% End: 

